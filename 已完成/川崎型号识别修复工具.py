#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import re
import time
import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin, urlparse
import json

class KawasakiModelFixer:
    def __init__(self):
        self.base_url = "https://kawasakirobotics.cn"
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        })
        
        # æœåŠ¡å™¨è·¯å¾„
        if os.path.exists("/srv/downloads/approved/"):
            self.base_dir = "/srv/downloads/approved/å·å´"
        else:
            self.base_dir = os.path.join(os.getcwd(), "downloads", "å·å´")
    
    def log(self, message):
        """æ—¥å¿—è¾“å‡º"""
        timestamp = time.strftime("%Y-%m-%d %H:%M:%S")
        print(f"[{timestamp}] {message}")
    
    def get_product_page_info(self, product_url):
        """è·å–äº§å“é¡µé¢ä¿¡æ¯ï¼Œå°è¯•æå–å®Œæ•´å‹å·"""
        try:
            self.log(f"ğŸ” æ­£åœ¨åˆ†æäº§å“é¡µé¢: {product_url}")
            
            response = self.session.get(product_url, timeout=30)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # ä»åˆ†ç±»é¡µé¢ç›´æ¥æå–æ‰€æœ‰äº§å“å‹å·
            content = soup.get_text()
            
            # æŸ¥æ‰¾æ‰€æœ‰å‹å·
            models = []
            
            # æ–¹æ³•1: æŸ¥æ‰¾æ‰€æœ‰å‹å·æ¨¡å¼
            model_patterns = [
                r'([A-Z]{1,3}\d{3}[NLHX]?)',  # RS003N, RS003Lç­‰
                r'([A-Z]{1,3}\d{3})\s*([NLHX])',  # RS003 N è¿™ç§æ ¼å¼
            ]
            
            for pattern in model_patterns:
                matches = re.findall(pattern, content, re.IGNORECASE)
                for match in matches:
                    if isinstance(match, tuple):
                        # å¤„ç†åˆ†ç¦»çš„æ ¼å¼
                        model = f"{match[0]}{match[1]}"
                    else:
                        model = match
                    
                    if model not in models:
                        models.append(model.upper())
            
            # æ–¹æ³•2: ä»é¡µé¢æ ‡é¢˜æå–
            title = soup.find('title')
            if title:
                title_text = title.get_text().strip()
                self.log(f"ğŸ“„ é¡µé¢æ ‡é¢˜: {title_text}")
                
                title_model = self.extract_model_from_text(title_text)
                if title_model and title_model not in models:
                    models.append(title_model)
            
            # æ–¹æ³•3: ä»URLè·¯å¾„æå–åŸºç¡€å‹å·
            url_model = self.extract_base_model_from_url(product_url)
            if url_model and url_model not in models:
                models.append(url_model)
            
            # å»é‡å¹¶æ’åº
            models = list(set(models))
            models.sort()
            
            if models:
                self.log(f"ğŸ·ï¸ ä»é¡µé¢æå–åˆ°å‹å·: {', '.join(models)}")
                return models
            else:
                self.log("âš ï¸ æœªä»é¡µé¢æå–åˆ°å‹å·ä¿¡æ¯")
                return None
            
        except Exception as e:
            self.log(f"âŒ è·å–äº§å“é¡µé¢ä¿¡æ¯å¤±è´¥: {str(e)}")
            return None
    
    def extract_model_from_text(self, text):
        """ä»æ–‡æœ¬ä¸­æå–å‹å·"""
        patterns = [
            r'([A-Z]{1,3}\d{3}[NLHX]?)',  # RS003N, RS003Lç­‰ï¼ŒåŒ…æ‹¬YF002N
            r'([A-Z]{1,3}\d{3})\s*([NLHX])',  # RS003 N è¿™ç§æ ¼å¼
        ]
        
        for pattern in patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                if len(match.groups()) == 2:
                    # å¤„ç†åˆ†ç¦»çš„æ ¼å¼
                    return f"{match.group(1)}{match.group(2)}"
                else:
                    return match.group(1)
        
        return None
    
    def extract_base_model_from_url(self, url):
        """ä»URLä¸­æå–åŸºç¡€å‹å·ï¼ˆä¸å«åç¼€ï¼‰"""
        try:
            parsed_url = urlparse(url)
            path_parts = parsed_url.path.strip('/').split('/')
            
            for part in path_parts:
                # åŒ¹é…åŸºç¡€å‹å·æ¨¡å¼ï¼ŒåŒ…æ‹¬Yå‰ç¼€
                match = re.search(r'([A-Z]{1,3}\d{3})', part, re.IGNORECASE)
                if match:
                    return match.group(1).upper()
            
            return None
            
        except Exception as e:
            self.log(f"âŒ ä»URLæå–åŸºç¡€å‹å·å¤±è´¥: {str(e)}")
            return None
    
    def get_base_model_from_full_model(self, full_model):
        """ä»å®Œæ•´å‹å·ä¸­æå–åŸºç¡€å‹å·ï¼ˆä¸å«åç¼€ï¼‰"""
        # åŒ¹é…æ¨¡å¼ï¼šå­—æ¯+æ•°å­—+å¯é€‰åç¼€
        match = re.match(r'^([A-Z]{1,3}\d{3})[NLHX]?$', full_model, re.IGNORECASE)
        if match:
            return match.group(1).upper()
        return None
    
    def find_matching_models(self, folder_name, model_mapping):
        """æŸ¥æ‰¾ä¸æ–‡ä»¶å¤¹åç§°åŒ¹é…çš„å‹å·"""
        matches = []
        
        # æ–¹æ³•1: ç›´æ¥åŒ¹é…å®Œæ•´å‹å·
        if folder_name in model_mapping:
            matches.extend(model_mapping[folder_name])
        
        # æ–¹æ³•2: æå–åŸºç¡€å‹å·ååŒ¹é…
        base_model = self.get_base_model_from_full_model(folder_name)
        if base_model and base_model in model_mapping:
            matches.extend(model_mapping[base_model])
        
        # æ–¹æ³•3: å¤„ç†ç¼ºå°‘å‰ç¼€çš„æƒ…å†µï¼ˆå¦‚F002 -> YF002ï¼‰
        if folder_name.startswith('F') and len(folder_name) >= 4:
            # å°è¯•æ·»åŠ Yå‰ç¼€
            y_prefixed = 'Y' + folder_name
            if y_prefixed in model_mapping:
                matches.extend(model_mapping[y_prefixed])
            
            # ä¹Ÿæ£€æŸ¥åŸºç¡€å‹å·
            y_base = self.get_base_model_from_full_model(y_prefixed)
            if y_base and y_base in model_mapping:
                matches.extend(model_mapping[y_base])
        
        # æ–¹æ³•4: å¤„ç†ç¼ºå°‘å‰ç¼€çš„æƒ…å†µï¼ˆå¦‚F002N -> YF002Nï¼‰
        if folder_name.startswith('F') and len(folder_name) >= 5:
            # å°è¯•æ·»åŠ Yå‰ç¼€
            y_prefixed = 'Y' + folder_name
            if y_prefixed in model_mapping:
                matches.extend(model_mapping[y_prefixed])
        
        return list(set(matches))  # å»é‡
    
    def select_best_match(self, folder_name, matching_models):
        """ä»å¤šä¸ªåŒ¹é…å‹å·ä¸­é€‰æ‹©æœ€ä½³åŒ¹é…"""
        if not matching_models:
            return None
        
        if len(matching_models) == 1:
            return matching_models[0]
        
        # ä¼˜å…ˆé€‰æ‹©ä¸æ–‡ä»¶å¤¹åç§°æœ€ç›¸ä¼¼çš„
        best_match = None
        best_score = 0
        
        for model in matching_models:
            score = 0
            
            # å®Œå…¨åŒ¹é…å¾—åˆ†æœ€é«˜
            if model == folder_name:
                score = 100
            # åŒ…å«å…³ç³»å¾—åˆ†æ¬¡ä¹‹
            elif folder_name in model or model in folder_name:
                score = 80
            # é•¿åº¦ç›¸ä¼¼å¾—åˆ†å†æ¬¡
            elif abs(len(model) - len(folder_name)) <= 1:
                score = 60
            # å‰ç¼€åŒ¹é…å¾—åˆ†
            elif model.startswith(folder_name[:3]) or folder_name.startswith(model[:3]):
                score = 40
            
            if score > best_score:
                best_score = score
                best_match = model
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å¥½çš„åŒ¹é…ï¼Œè¿”å›ç¬¬ä¸€ä¸ª
        if best_match is None:
            best_match = matching_models[0]
        
        return best_match
    
    def infer_model_suffix(self, base_model, content):
        """æ¨æ–­å‹å·åç¼€"""
        try:
            # åœ¨å†…å®¹ä¸­æŸ¥æ‰¾åŒ…å«åŸºç¡€å‹å·çš„å®Œæ•´å‹å·
            pattern = f"{base_model}[NLHX]"
            matches = re.findall(pattern, content, re.IGNORECASE)
            
            if matches:
                return matches[0].upper()
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œå°è¯•ä»äº§å“ç‰¹æ€§æ¨æ–­
            if 'è´Ÿè½½' in content or 'payload' in content.lower():
                # æ ¹æ®è´Ÿè½½ä¿¡æ¯æ¨æ–­åç¼€
                if '80kg' in content or '80 kg' in content:
                    return f"{base_model}N"  # æ ‡å‡†è´Ÿè½½
                elif '150kg' in content or '150 kg' in content:
                    return f"{base_model}L"  # é•¿è‡‚
                elif '300kg' in content or '300 kg' in content:
                    return f"{base_model}H"  # é«˜è´Ÿè½½
            
            # é»˜è®¤è¿”å›åŸºç¡€å‹å·
            return base_model
            
        except Exception as e:
            self.log(f"âŒ æ¨æ–­å‹å·åç¼€å¤±è´¥: {str(e)}")
            return base_model
    
    def find_product_urls(self):
        """æŸ¥æ‰¾æ‰€æœ‰äº§å“é¡µé¢çš„URL"""
        try:
            self.log("ğŸ” æ­£åœ¨æŸ¥æ‰¾äº§å“é¡µé¢URL...")
            
            # æœºå™¨äººäº§å“é¡µé¢
            robot_urls = [
                'https://kawasakirobotics.cn/robots-category/small-medium-payloads/',
                'https://kawasakirobotics.cn/robots-category/large-payloads/',
                'https://kawasakirobotics.cn/robots-category/extra-large-payloads/',
                'https://kawasakirobotics.cn/robots-category/dual-arm-scara/',
                'https://kawasakirobotics.cn/robots-category/palletizing/',
                'https://kawasakirobotics.cn/robots-category/pick-and-place/',
                'https://kawasakirobotics.cn/robots-category/medical/',
                'https://kawasakirobotics.cn/robots-category/arc-welding/',
                'https://kawasakirobotics.cn/robots-category/painting/',
                'https://kawasakirobotics.cn/robots-category/wafer/'
            ]
            
            product_urls = []
            
            for category_url in robot_urls:
                try:
                    self.log(f"ğŸ” æ­£åœ¨åˆ†æåˆ†ç±»é¡µé¢: {category_url}")
                    
                    response = self.session.get(category_url, timeout=30)
                    response.raise_for_status()
                    
                    soup = BeautifulSoup(response.content, 'html.parser')
                    
                    # ç›´æ¥ä»åˆ†ç±»é¡µé¢æå–äº§å“ä¿¡æ¯ï¼Œè€Œä¸æ˜¯å¯»æ‰¾producté“¾æ¥
                    # å·å´å®˜ç½‘çš„äº§å“ä¿¡æ¯æ˜¯ç›´æ¥åœ¨åˆ†ç±»é¡µé¢ä¸Šçš„
                    product_urls.append(category_url)
                    
                    time.sleep(1)  # é¿å…è¯·æ±‚è¿‡å¿«
                    
                except Exception as e:
                    self.log(f"âŒ åˆ†æåˆ†ç±»é¡µé¢å¤±è´¥ {category_url}: {str(e)}")
                    continue
            
            self.log(f"âœ… æ‰¾åˆ° {len(product_urls)} ä¸ªåˆ†ç±»é¡µé¢")
            return product_urls
            
        except Exception as e:
            self.log(f"âŒ æŸ¥æ‰¾äº§å“é¡µé¢å¤±è´¥: {str(e)}")
            return []
    
    def create_model_mapping(self):
        """åˆ›å»ºå‹å·æ˜ å°„è¡¨"""
        try:
            self.log("ğŸ” æ­£åœ¨åˆ›å»ºå‹å·æ˜ å°„è¡¨...")
            
            product_urls = self.find_product_urls()
            model_mapping = {}
            
            for i, url in enumerate(product_urls):
                self.log(f"ğŸ“Š è¿›åº¦: {i+1}/{len(product_urls)}")
                
                models = self.get_product_page_info(url)
                if models:
                    # å¤„ç†è¿”å›çš„å‹å·åˆ—è¡¨
                    for model in models:
                        # æå–åŸºç¡€å‹å·ï¼ˆä¸å«åç¼€ï¼‰
                        base_model = re.match(r'([A-Z]{1,3}\d{3})', model)
                        if base_model:
                            base = base_model.group(1)
                            if base not in model_mapping:
                                model_mapping[base] = []
                            if model not in model_mapping[base]:
                                model_mapping[base].append(model)
                
                time.sleep(0.5)  # é¿å…è¯·æ±‚è¿‡å¿«
            
            # ä¿å­˜æ˜ å°„è¡¨
            mapping_file = os.path.join(self.base_dir, 'model_mapping.json')
            with open(mapping_file, 'w', encoding='utf-8') as f:
                json.dump(model_mapping, f, ensure_ascii=False, indent=2)
            
            self.log(f"âœ… å‹å·æ˜ å°„è¡¨å·²ä¿å­˜åˆ°: {mapping_file}")
            return model_mapping
            
        except Exception as e:
            self.log(f"âŒ åˆ›å»ºå‹å·æ˜ å°„è¡¨å¤±è´¥: {str(e)}")
            return {}
    
    def fix_existing_folders(self):
        """ä¿®å¤ç°æœ‰æ–‡ä»¶å¤¹çš„å‘½å"""
        try:
            self.log("ğŸ”§ æ­£åœ¨ä¿®å¤ç°æœ‰æ–‡ä»¶å¤¹å‘½å...")
            
            # åŠ è½½å‹å·æ˜ å°„è¡¨
            mapping_file = os.path.join(self.base_dir, 'model_mapping.json')
            if not os.path.exists(mapping_file):
                self.log("âŒ å‹å·æ˜ å°„è¡¨ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œ create_model_mapping()")
                return
            
            with open(mapping_file, 'r', encoding='utf-8') as f:
                model_mapping = json.load(f)
            
            # å®šä¹‰æ‰€æœ‰æœºå™¨äººç±»åˆ«ç›®å½•
            robot_categories = [
                'SCARAæœºå™¨äºº',
                'ä¸­å°å‹é€šç”¨æœºå™¨äºº~80kgè´Ÿè½½',
                'åŒ»è¯æœºå™¨äºº', 
                'åä½œæœºå™¨äºº',
                'å–·æ¶‚æœºå™¨äºº',
                'å¤§å‹é€šç”¨æœºå™¨äºº~300kgè´Ÿè½½',
                'æ™¶åœ†æ¬è¿æœºå™¨äºº',
                'æ¶‚èƒ¶æœºå™¨äºº',
                'ç„Šæ¥_åˆ‡å‰²æœºå™¨äºº',
                'ç å›æœºå™¨äºº',
                'è¶…å¤§å‹é€šç”¨æœºå™¨äºº~1,500kgè´Ÿè½½',
                'é«˜é€Ÿåˆ†æ‹£æœºå™¨äºº'
            ]
            
            total_fixed = 0
            
            for category in robot_categories:
                robot_dir = os.path.join(self.base_dir, 'æœºå™¨äºº', category)
                if not os.path.exists(robot_dir):
                    self.log(f"âš ï¸ ç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡: {robot_dir}")
                    continue
                
                self.log(f"ğŸ”§ æ­£åœ¨ä¿®å¤ç±»åˆ«: {category}")
                category_fixed = 0
                
                for item in os.listdir(robot_dir):
                    item_path = os.path.join(robot_dir, item)
                    
                    if os.path.isdir(item_path):
                        # ä½¿ç”¨æ–°çš„åŒ¹é…æ–¹æ³•æŸ¥æ‰¾å¯¹åº”çš„å‹å·
                        matching_models = self.find_matching_models(item, model_mapping)
                        
                        if matching_models:
                            if len(matching_models) == 1:
                                # åªæœ‰ä¸€ä¸ªåŒ¹é…å‹å·ï¼Œç›´æ¥é‡å‘½å
                                new_name = matching_models[0]
                                new_path = os.path.join(robot_dir, new_name)
                                
                                if not os.path.exists(new_path):
                                    try:
                                        os.rename(item_path, new_path)
                                        self.log(f"  âœ… é‡å‘½å: {item} -> {new_name}")
                                        category_fixed += 1
                                    except Exception as e:
                                        self.log(f"  âŒ é‡å‘½åå¤±è´¥ {item}: {str(e)}")
                                else:
                                    self.log(f"  âš ï¸ ç›®æ ‡æ–‡ä»¶å¤¹å·²å­˜åœ¨: {new_name}")
                            
                            elif len(matching_models) > 1:
                                # å¤šä¸ªåŒ¹é…å‹å·ï¼Œéœ€è¦ç”¨æˆ·é€‰æ‹©
                                self.log(f"  ğŸ” {item} æœ‰å¤šä¸ªå‹å·é€‰æ‹©: {matching_models}")
                                # ä¼˜å…ˆé€‰æ‹©ä¸æ–‡ä»¶å¤¹åç§°æœ€åŒ¹é…çš„
                                best_match = self.select_best_match(item, matching_models)
                                if best_match:
                                    new_path = os.path.join(robot_dir, best_match)
                                    if not os.path.exists(new_path):
                                        try:
                                            os.rename(item_path, new_path)
                                            self.log(f"  âœ… é‡å‘½å: {item} -> {best_match}")
                                            category_fixed += 1
                                        except Exception as e:
                                            self.log(f"  âŒ é‡å‘½åå¤±è´¥ {item}: {str(e)}")
                                    else:
                                        self.log(f"  âš ï¸ ç›®æ ‡æ–‡ä»¶å¤¹å·²å­˜åœ¨: {best_match}")
                        else:
                            self.log(f"  âš ï¸ æœªæ‰¾åˆ°åŒ¹é…å‹å·: {item}")
                
                if category_fixed > 0:
                    self.log(f"  ğŸ“Š ç±»åˆ« {category} ä¿®å¤äº† {category_fixed} ä¸ªæ–‡ä»¶å¤¹")
                else:
                    self.log(f"  ğŸ“Š ç±»åˆ« {category} æ— éœ€ä¿®å¤")
                
                total_fixed += category_fixed
            
            self.log(f"âœ… ä¿®å¤å®Œæˆï¼Œå…±ä¿®å¤ {total_fixed} ä¸ªæ–‡ä»¶å¤¹")
            
        except Exception as e:
            self.log(f"âŒ ä¿®å¤æ–‡ä»¶å¤¹å¤±è´¥: {str(e)}")
    
    def show_folder_status(self):
        """æ˜¾ç¤ºæ–‡ä»¶å¤¹çŠ¶æ€"""
        try:
            # å®šä¹‰æ‰€æœ‰æœºå™¨äººç±»åˆ«ç›®å½•
            robot_categories = [
                'SCARAæœºå™¨äºº',
                'ä¸­å°å‹é€šç”¨æœºå™¨äºº~80kgè´Ÿè½½',
                'åŒ»è¯æœºå™¨äºº', 
                'åä½œæœºå™¨äºº',
                'å–·æ¶‚æœºå™¨äºº',
                'å¤§å‹é€šç”¨æœºå™¨äºº~300kgè´Ÿè½½',
                'æ™¶åœ†æ¬è¿æœºå™¨äºº',
                'æ¶‚èƒ¶æœºå™¨äºº',
                'ç„Šæ¥_åˆ‡å‰²æœºå™¨äºº',
                'ç å›æœºå™¨äºº',
                'è¶…å¤§å‹é€šç”¨æœºå™¨äºº~1,500kgè´Ÿè½½',
                'é«˜é€Ÿåˆ†æ‹£æœºå™¨äºº'
            ]
            
            total_folders = 0
            total_need_fix = 0
            
            for category in robot_categories:
                robot_dir = os.path.join(self.base_dir, 'æœºå™¨äºº', category)
                if not os.path.exists(robot_dir):
                    self.log(f"âš ï¸ ç›®å½•ä¸å­˜åœ¨: {robot_dir}")
                    continue
                
                self.log(f"ğŸ“Š ç±»åˆ«: {category}")
                self.log("-" * 40)
                
                folders = os.listdir(robot_dir)
                folders.sort()
                category_folders = 0
                category_need_fix = 0
                
                for folder in folders:
                    if os.path.isdir(os.path.join(robot_dir, folder)):
                        category_folders += 1
                        # æ£€æŸ¥æ˜¯å¦åŒ…å«åç¼€å’Œå‰ç¼€
                        if re.match(r'^[A-Z]{1,3}\d{3}[NLHX]$', folder):
                            status = "âœ… æ­£ç¡®"
                        elif folder.startswith('F') and len(folder) >= 4:
                            # æ£€æŸ¥æ˜¯å¦æ˜¯ç¼ºå°‘Yå‰ç¼€çš„å‹å·
                            status = "âŒ ç¼ºå°‘Yå‰ç¼€"
                            category_need_fix += 1
                        elif re.match(r'^[A-Z]{1,3}\d{3}$', folder):
                            status = "âŒ ç¼ºå°‘åç¼€"
                            category_need_fix += 1
                        else:
                            status = "âŒ æ ¼å¼é”™è¯¯"
                            category_need_fix += 1
                        
                        self.log(f"  {folder:<15} {status}")
                
                self.log(f"  æ€»è®¡: {category_folders} ä¸ªæ–‡ä»¶å¤¹, éœ€è¦ä¿®å¤: {category_need_fix} ä¸ª")
                self.log("")
                
                total_folders += category_folders
                total_need_fix += category_need_fix
            
            self.log("=" * 50)
            self.log(f"ğŸ“Š æ€»ä½“ç»Ÿè®¡: å…± {total_folders} ä¸ªæ–‡ä»¶å¤¹, éœ€è¦ä¿®å¤ {total_need_fix} ä¸ª")
            self.log("=" * 50)
            
        except Exception as e:
            self.log(f"âŒ æ˜¾ç¤ºæ–‡ä»¶å¤¹çŠ¶æ€å¤±è´¥: {str(e)}")

def main():
    """ä¸»å‡½æ•°"""
    fixer = KawasakiModelFixer()
    
    print("ğŸ”§ å·å´æœºå™¨äººå‹å·è¯†åˆ«ä¿®å¤å·¥å…·")
    print("=" * 50)
    print("1. æ˜¾ç¤ºå½“å‰æ–‡ä»¶å¤¹çŠ¶æ€")
    print("2. åˆ›å»ºå‹å·æ˜ å°„è¡¨")
    print("3. ä¿®å¤ç°æœ‰æ–‡ä»¶å¤¹")
    print("4. é€€å‡º")
    print("=" * 50)
    
    while True:
        try:
            choice = input("è¯·é€‰æ‹©æ“ä½œ (1-4): ").strip()
            
            if choice == '1':
                fixer.show_folder_status()
            elif choice == '2':
                fixer.create_model_mapping()
            elif choice == '3':
                fixer.fix_existing_folders()
            elif choice == '4':
                print("ğŸ‘‹ å†è§ï¼")
                break
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ 1-4")
            
            print()
            
        except KeyboardInterrupt:
            print("\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­ï¼Œå†è§ï¼")
            break
        except Exception as e:
            print(f"âŒ æ“ä½œå¤±è´¥: {str(e)}")

if __name__ == "__main__":
    main()
