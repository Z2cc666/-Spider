#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åº“å¡ä¸‹è½½ä¸­å¿ƒçˆ¬è™«
çˆ¬å–åº“å¡ä¸‹è½½ä¸­å¿ƒçš„æ‰€æœ‰èµ„æ–™æ–‡ä»¶
æ”¯æŒé’‰é’‰é€šçŸ¥å’Œè‡ªåŠ¨æ£€æµ‹æ–°æ–‡ä»¶
æ–°å¢Seleniumæ»šåŠ¨åŠ è½½åŠŸèƒ½ï¼Œç¡®ä¿è·å–å®Œæ•´æ•°æ®
"""

import requests
from bs4 import BeautifulSoup
import json
import time
import os
import pickle
import hmac
import hashlib
import base64
from datetime import datetime
from urllib.parse import urljoin, urlparse, quote_plus
import re
import urllib.request
import argparse

# æ–°å¢Seleniumç›¸å…³å¯¼å…¥
try:
    from selenium import webdriver
    from selenium.webdriver.common.by import By
    from selenium.webdriver.support.ui import WebDriverWait
    from selenium.webdriver.support import expected_conditions as EC
    from selenium.webdriver.chrome.options import Options
    SELENIUM_AVAILABLE = True
except ImportError:
    SELENIUM_AVAILABLE = False
    print("è­¦å‘Š: Seleniumæœªå®‰è£…ï¼Œå°†ä½¿ç”¨ä¼ ç»ŸAPIæ–¹å¼")

class KukaSpider:
    def __init__(self):
        self.base_url = "https://www.kuka.cn"
        
        # ä¸­æ–‡ç½‘ç«™é…ç½®
        self.cn_config = {
            'main_url': "https://www.kuka.cn/zh-cn/services/downloads",
            'api_refinements_url': "https://www.kuka.cn/zh-cn/api/downloadcentersearch/Refinements",
            'api_results_url': "https://www.kuka.cn/zh-cn/api/downloadcentersearch/Results",
            'selenium_url': "https://www.kuka.cn/zh-cn/services/downloads",
            'language': 'zh-cn',
            'folder_name': 'ä¸­æ–‡ç½‘ç«™'
        }
        
        # è‹±æ–‡ç½‘ç«™é…ç½®
        self.en_config = {
            'main_url': "https://www.kuka.com/en-de/services/downloads",
            'api_refinements_url': "https://www.kuka.com/en-de/api/downloadcentersearch/Refinements",
            'api_results_url': "https://www.kuka.com/en-de/api/downloadcentersearch/Results",
            'selenium_url': "https://www.kuka.com/en-de/downloads",
            'language': 'en-de',
            'folder_name': 'è‹±æ–‡ç½‘ç«™'
        }
        
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'application/json, text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
        }
        self.session = requests.Session()
        self.session.headers.update(self.headers)
        
        # æœåŠ¡å™¨å›ºå®šè·¯å¾„ï¼ˆæŒ‰è§„èŒƒè¦æ±‚ï¼‰ï¼Œæœ¬åœ°æµ‹è¯•ä½¿ç”¨å½“å‰ç›®å½•
        if os.path.exists("/srv/downloads/approved/"):
            self.base_dir = "/srv/downloads/approved/åº“å¡"
            self.output_dir = os.path.join(self.base_dir, "äº§å“æ•°æ®")
            self.download_dir = os.path.join(self.base_dir, "èµ„æ–™ä¸‹è½½")
        else:
            # æœ¬åœ°æµ‹è¯•ç¯å¢ƒ
            self.base_dir = os.path.join(os.getcwd(), "åº“å¡")
            self.output_dir = os.path.join(self.base_dir, "äº§å“æ•°æ®")
            self.download_dir = os.path.join(self.base_dir, "èµ„æ–™ä¸‹è½½")
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(self.output_dir, exist_ok=True)
        os.makedirs(self.download_dir, exist_ok=True)
        
        # é’‰é’‰é…ç½®ï¼ˆå†…ç½®ï¼‰
        self.dingtalk_config = {
            "access_token": "1a431b6482e59ec652a6eab37705d50fd282dc426f0b829b3eb9a9c1b277ed24",
            "secret": "SECc5e2168011dd97d4c511e06832d172f31635ef635771668e4e6003fce23c07bb",
            "webhook_url": "https://oapi.dingtalk.com/robot/send?access_token=1a431b6482e59ec652a6eab37705d50fd282dc426f0b829b3eb9a9c1b277ed24"
        }
        
        # åŠ è½½å·²å¤„ç†çš„æ–‡ä»¶è®°å½•
        self.processed_files = self.load_processed_files()
        self.new_files = []
        
        # åˆ¤æ–­æ˜¯å¦ä¸ºé¦–æ¬¡è¿è¡Œ
        self.is_first_run = not os.path.exists(os.path.join(self.base_dir, 'processed_files.pkl'))
        
        # è·³è¿‡çš„åˆ†ç±»ï¼ˆæ ¹æ®ç”¨æˆ·è¦æ±‚ï¼Œä½†ä¿ç•™Brochureså’ŒDataSheetsåˆ†ç±»ï¼‰
        self.skip_categories = ['è½¯ä»¶', 'CAD', 'Software']
        
        # Seleniumé…ç½®
        self.use_selenium = SELENIUM_AVAILABLE
        if not self.use_selenium:
            print("âš ï¸ Seleniumä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨ä¼ ç»ŸAPIæ–¹å¼")
    
    def load_processed_files(self):
        """åŠ è½½å·²å¤„ç†çš„æ–‡ä»¶è®°å½•"""
        processed_file = os.path.join(self.base_dir, 'processed_files.pkl')
        if os.path.exists(processed_file):
            try:
                with open(processed_file, 'rb') as f:
                    return pickle.load(f)
            except:
                return set()
        return set()
    
    def save_processed_files(self):
        """ä¿å­˜å·²å¤„ç†çš„æ–‡ä»¶è®°å½•"""
        processed_file = os.path.join(self.base_dir, 'processed_files.pkl')
        with open(processed_file, 'wb') as f:
            pickle.dump(self.processed_files, f)
    
    def log(self, message):
        """æ—¥å¿—è®°å½•"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        print(f"[{timestamp}] {message}")
    
    def send_dingtalk_notification(self, message):
        """å‘é€é’‰é’‰é€šçŸ¥ï¼ˆæ”¯æŒåŠ å¯†ç­¾åï¼‰"""
        if not self.dingtalk_config or not self.dingtalk_config.get('webhook_url'):
            self.log("âš ï¸ é’‰é’‰é…ç½®æœªè®¾ç½®ï¼Œè·³è¿‡é€šçŸ¥")
            return
        
        try:
            # è·å–é…ç½®
            access_token = self.dingtalk_config.get('access_token', '')
            secret = self.dingtalk_config.get('secret', '')
            webhook_url = self.dingtalk_config.get('webhook_url', '')
            
            # å¦‚æœæœ‰secretï¼Œç”Ÿæˆç­¾å
            if secret:
                timestamp = str(round(time.time() * 1000))
                string_to_sign = f'{timestamp}\n{secret}'
                hmac_code = hmac.new(
                    secret.encode('utf-8'),
                    string_to_sign.encode('utf-8'),
                    digestmod=hashlib.sha256
                ).digest()
                sign = quote_plus(base64.b64encode(hmac_code))
                webhook_url = f"{webhook_url}&timestamp={timestamp}&sign={sign}"
            
            # æ„å»ºæ¶ˆæ¯
            data = {
                "msgtype": "text",
                "text": {
                    "content": f"ğŸ¤– åº“å¡çˆ¬è™«é€šçŸ¥\n{message}"
                }
            }
            
            # å‘é€é€šçŸ¥
            response = requests.post(
                webhook_url,
                json=data,
                headers={'Content-Type': 'application/json'},
                timeout=10
            )
            
            if response.status_code == 200:
                result = response.json()
                if result.get('errcode') == 0:
                    self.log("âœ… é’‰é’‰é€šçŸ¥å‘é€æˆåŠŸ")
                else:
                    self.log(f"âŒ é’‰é’‰é€šçŸ¥å‘é€å¤±è´¥: {result.get('errmsg', 'æœªçŸ¥é”™è¯¯')}")
            else:
                self.log(f"âŒ é’‰é’‰é€šçŸ¥HTTPé”™è¯¯: {response.status_code}")
                
        except Exception as e:
            self.log(f"âŒ é’‰é’‰é€šçŸ¥å‘é€å¼‚å¸¸: {str(e)}")
    
    def get_page(self, url, max_retries=3):
        """è·å–é¡µé¢å†…å®¹ï¼Œå¸¦é‡è¯•æœºåˆ¶"""
        for attempt in range(max_retries):
            try:
                response = self.session.get(url, timeout=15)
                response.raise_for_status()
                response.encoding = 'utf-8'
                return response.text
            except requests.exceptions.HTTPError as e:
                if e.response.status_code == 502 and attempt < max_retries - 1:
                    print(f"è·å–é¡µé¢å¤±è´¥ {url}: {e} (å°è¯• {attempt + 1}/{max_retries})")
                    time.sleep(5 * (attempt + 1))  # é€’å¢å»¶è¿Ÿ
                    continue
                else:
                    print(f"è·å–é¡µé¢å¤±è´¥ {url}: {e}")
                    return None
            except Exception as e:
                if attempt < max_retries - 1:
                    print(f"è·å–é¡µé¢å¤±è´¥ {url}: {e} (å°è¯• {attempt + 1}/{max_retries})")
                    time.sleep(3 * (attempt + 1))
                    continue
                else:
                    print(f"è·å–é¡µé¢å¤±è´¥ {url}: {e}")
                    return None
        return None
    
    def get_api_data(self, url, params=None, max_retries=3):
        """è·å–APIæ•°æ®ï¼Œå¸¦é‡è¯•æœºåˆ¶"""
        for attempt in range(max_retries):
            try:
                response = self.session.get(url, params=params, timeout=15)
                response.raise_for_status()
                return response.json()
            except requests.exceptions.HTTPError as e:
                if e.response.status_code == 502 and attempt < max_retries - 1:
                    print(f"è·å–APIæ•°æ®å¤±è´¥ {url}: {e} (å°è¯• {attempt + 1}/{max_retries})")
                    time.sleep(5 * (attempt + 1))  # é€’å¢å»¶è¿Ÿ
                    continue
                else:
                    print(f"è·å–APIæ•°æ®å¤±è´¥ {url}: {e}")
                    return None
            except Exception as e:
                if attempt < max_retries - 1:
                    print(f"è·å–APIæ•°æ®å¤±è´¥ {url}: {e} (å°è¯• {attempt + 1}/{max_retries})")
                    time.sleep(3 * (attempt + 1))
                    continue
                else:
                    print(f"è·å–APIæ•°æ®å¤±è´¥ {url}: {e}")
                    return None
        return None
    
    def get_categories(self, config):
        """è·å–æŒ‡å®šç½‘ç«™çš„æ‰€æœ‰åˆ†ç±»ä¿¡æ¯"""
        print(f"æ­£åœ¨è·å–{config['folder_name']}åˆ†ç±»ä¿¡æ¯...")
        
        # è·å–åˆ†ç±»æ•°æ®
        data = self.get_api_data(config['api_refinements_url'])
        if not data:
            return []
        
        categories = []
        
        # è§£æåˆ†ç±»æ•°æ®
        if 'refinements' in data:
            for refinement in data['refinements']:
                if refinement.get('termId') == 'Category':
                    for facet in refinement.get('facets', []):
                        term = facet.get('term', {})
                        category_name = term.get('label', '')
                        category_count = facet.get('count', 0)
                        
                        # è·³è¿‡è½¯ä»¶å’ŒCADåˆ†ç±»
                        if category_name in self.skip_categories:
                            print(f"è·³è¿‡åˆ†ç±»: {category_name} ({category_count} ä¸ªæ–‡ä»¶)")
                            continue
                        
                        # è·³è¿‡å¤–éƒ¨é“¾æ¥ï¼ˆCADï¼‰
                        if category_name == 'CAD':
                            print(f"è·³è¿‡å¤–éƒ¨é“¾æ¥åˆ†ç±»: {category_name}")
                            continue
                        
                        if category_count > 0:
                            categories.append({
                                'name': category_name,
                                'value_id': term.get('valueId', ''),
                                'count': category_count,
                                'term_id': 'Category',
                                'website': config['folder_name']
                            })
                            print(f"æ‰¾åˆ°åˆ†ç±»: {category_name} ({category_count} ä¸ªæ–‡ä»¶)")
        
        return categories
    
    def get_downloads_by_category_selenium(self, category, config):
        """ä½¿ç”¨Seleniumæ»šåŠ¨åŠ è½½è·å–æŸä¸ªåˆ†ç±»çš„æ‰€æœ‰ä¸‹è½½æ–‡ä»¶"""
        if not self.use_selenium:
            self.log("Seleniumä¸å¯ç”¨ï¼Œå›é€€åˆ°APIæ–¹å¼")
            return self.get_all_downloads_by_category(category, config)
        
        self.log(f"ä½¿ç”¨Seleniumè·å–{category['website']}åˆ†ç±» '{category['name']}' çš„æ–‡ä»¶...")
        
        # é…ç½®Chromeé€‰é¡¹
        chrome_options = Options()
        chrome_options.add_argument('--headless')  # æ— å¤´æ¨¡å¼
        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--disable-dev-shm-usage')
        chrome_options.add_argument('--disable-gpu')
        chrome_options.add_argument('--window-size=1920,1080')
        chrome_options.add_argument('--user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
        
        driver = None
        try:
            # åˆ›å»ºWebDriver
            driver = webdriver.Chrome(options=chrome_options)
            self.log("Chrome WebDriveråˆ›å»ºæˆåŠŸ")
            
            # è®¿é—®ä¸‹è½½ä¸­å¿ƒé¡µé¢
            url = config['selenium_url']
            self.log(f"è®¿é—®é¡µé¢: {url}")
            driver.get(url)
            
            # ç­‰å¾…é¡µé¢åŠ è½½
            self.log("ç­‰å¾…é¡µé¢åŠ è½½...")
            time.sleep(10)
            
            # ç­‰å¾…ä¸‹è½½ä¸­å¿ƒç»„ä»¶åŠ è½½
            try:
                WebDriverWait(driver, 30).until(
                    EC.presence_of_element_located((By.CLASS_NAME, "mod-downloadcenter"))
                )
                self.log("ä¸‹è½½ä¸­å¿ƒç»„ä»¶åŠ è½½å®Œæˆ")
            except Exception as e:
                self.log(f"ç­‰å¾…ä¸‹è½½ä¸­å¿ƒç»„ä»¶è¶…æ—¶: {e}")
                return []
            
            # æŸ¥æ‰¾å¹¶ç‚¹å‡»æŒ‡å®šåˆ†ç±»
            self.log(f"æŸ¥æ‰¾å¹¶ç‚¹å‡»åˆ†ç±»: {category['name']}")
            try:
                # æŸ¥æ‰¾åˆ†ç±»é“¾æ¥
                category_links = driver.find_elements(By.CSS_SELECTOR, ".item__link__text")
                self.log(f"æ‰¾åˆ°åˆ†ç±»é“¾æ¥æ•°é‡: {len(category_links)}")
                
                target_category = None
                for link in category_links:
                    if category['name'] in link.text:
                        target_category = link
                        self.log(f"æ‰¾åˆ°ç›®æ ‡åˆ†ç±»é“¾æ¥: {link.text}")
                        break
                
                if target_category:
                    # ç‚¹å‡»åˆ†ç±»
                    self.log(f"ç‚¹å‡»åˆ†ç±»: {category['name']}")
                    driver.execute_script("arguments[0].click();", target_category)
                    time.sleep(5)
                    
                    # ç­‰å¾…ç»“æœåŠ è½½
                    try:
                        WebDriverWait(driver, 20).until(
                            EC.presence_of_element_located((By.CLASS_NAME, "mod-downloadcenter__results__item"))
                        )
                        self.log("åˆ†ç±»ç»“æœåŠ è½½å®Œæˆ")
                    except Exception as e:
                        self.log(f"ç­‰å¾…åˆ†ç±»ç»“æœè¶…æ—¶: {e}")
                        return []
                    
                    # æ»šåŠ¨åŠ è½½æ›´å¤šå†…å®¹
                    self.log("å¼€å§‹æ»šåŠ¨åŠ è½½æ›´å¤šå†…å®¹...")
                    all_files = []
                    previous_count = 0
                    scroll_attempts = 0
                    max_scroll_attempts = 50  # æœ€å¤§æ»šåŠ¨æ¬¡æ•°
                    
                    while scroll_attempts < max_scroll_attempts:
                        # è·å–å½“å‰ç»“æœé¡¹æ•°é‡
                        result_items = driver.find_elements(By.CLASS_NAME, "mod-downloadcenter__results__item")
                        current_count = len(result_items)
                        
                        self.log(f"æ»šåŠ¨å°è¯• {scroll_attempts + 1}: å½“å‰ç»“æœæ•°é‡: {current_count}")
                        
                        if current_count > previous_count:
                            self.log(f"å‘ç°æ–°å†…å®¹ï¼æ•°é‡ä» {previous_count} å¢åŠ åˆ° {current_count}")
                            previous_count = current_count
                            scroll_attempts = 0  # é‡ç½®è®¡æ•°å™¨
                        else:
                            scroll_attempts += 1
                        
                        # æ»šåŠ¨åˆ°é¡µé¢åº•éƒ¨
                        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                        time.sleep(2)
                        
                        # å†æ¬¡æ»šåŠ¨ä¸€ç‚¹ï¼Œç¡®ä¿è§¦å‘åŠ è½½
                        driver.execute_script("window.scrollTo(0, document.body.scrollHeight + 100);")
                        time.sleep(3)
                        
                        # æ£€æŸ¥æ˜¯å¦æœ‰åŠ è½½æŒ‡ç¤ºå™¨
                        try:
                            loading_indicators = driver.find_elements(By.CSS_SELECTOR, ".loading, .spinner, [class*='loading'], [class*='spinner']")
                            if loading_indicators:
                                self.log("æ£€æµ‹åˆ°åŠ è½½æŒ‡ç¤ºå™¨ï¼Œç­‰å¾…åŠ è½½å®Œæˆ...")
                                time.sleep(5)
                        except:
                            pass
                        
                        # å¦‚æœè¿ç»­å¤šæ¬¡æ²¡æœ‰æ–°å†…å®¹ï¼Œå¯èƒ½å·²ç»åŠ è½½å®Œæˆ
                        if scroll_attempts >= 10:
                            self.log("è¿ç»­10æ¬¡æ²¡æœ‰æ–°å†…å®¹ï¼Œå¯èƒ½å·²åŠ è½½å®Œæˆ")
                            break
                    
                    self.log(f"æ»šåŠ¨åŠ è½½å®Œæˆï¼Œæœ€ç»ˆç»“æœæ•°é‡: {len(result_items)}")
                    
                    # è§£ææ‰€æœ‰ç»“æœé¡¹
                    self.log("è§£ææ‰€æœ‰æ–‡ä»¶...")
                    for i, item in enumerate(result_items):
                        try:
                            # è·å–æ ‡é¢˜
                            title_elem = item.find_element(By.CSS_SELECTOR, ".m-results__list-item-headline span")
                            title = title_elem.text
                            
                            # è·å–åˆ†ç±»
                            category_elem = item.find_element(By.CSS_SELECTOR, ".item__caption")
                            category_name = category_elem.text
                            
                            # è·å–ä¸‹è½½é“¾æ¥
                            link_elem = item.find_element(By.CSS_SELECTOR, "a")
                            download_url = link_elem.get_attribute("href")
                            
                            # è·å–æè¿°
                            try:
                                desc_elem = item.find_element(By.CSS_SELECTOR, ".copy span")
                                description = desc_elem.text
                            except:
                                description = ""
                            
                            # è·å–ä¿®æ”¹æ—¶é—´
                            try:
                                modified_elem = item.find_element(By.CSS_SELECTOR, ".item__caption--modified")
                                modified = modified_elem.text
                            except:
                                modified = ""
                            
                            # æ¸…ç†æ ‡é¢˜
                            clean_title = title
                            if title and ' - ' in title:
                                parts = title.split(' - ')
                                if len(parts) > 1:
                                    last_part = parts[-1]
                                    if any(ext in last_part.upper() for ext in ['.PDF', '.DOC', '.XLS', '.ZIP', 'KB', 'MB']):
                                        clean_title = ' - '.join(parts[:-1])
                            
                            file_info = {
                                'url': download_url,
                                'title': clean_title,
                                'original_title': title,
                                'description': description,
                                'filetype': '',
                                'filesize': '',
                                'category': category_name,
                                'modified': modified,
                                'page': 1,
                                'website': category['website']
                            }
                            
                            all_files.append(file_info)
                            
                        except Exception as e:
                            self.log(f"è§£æç¬¬{i+1}é¡¹æ—¶å‡ºé”™: {e}")
                            continue
                    
                    self.log(f"é€šè¿‡Seleniumè·å–åˆ° {len(all_files)} ä¸ªæ–‡ä»¶")
                    return all_files
                    
                else:
                    self.log(f"æœªæ‰¾åˆ°åˆ†ç±»: {category['name']}")
                    return []
                    
            except Exception as e:
                self.log(f"å¤„ç†åˆ†ç±»æ—¶å‡ºé”™: {e}")
                import traceback
                traceback.print_exc()
                return []
                
        except Exception as e:
            self.log(f"Seleniumå¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
            return []
            
        finally:
            if driver:
                try:
                    driver.quit()
                    self.log("WebDriverå·²å…³é—­")
                except:
                    pass
    
    def get_downloads_by_category(self, category, config, page_number=1):
        """æ ¹æ®åˆ†ç±»è·å–ä¸‹è½½æ–‡ä»¶åˆ—è¡¨"""
        print(f"æ­£åœ¨è·å–{category['website']}åˆ†ç±» '{category['name']}' ç¬¬ {page_number} é¡µçš„æ–‡ä»¶...")
        
        # æ„å»ºAPIå‚æ•°ï¼Œæ ¹æ®ç½‘ç«™è¯­è¨€è®¾ç½®Languageå‚æ•°
        language_param = "zh:1" if config['language'] == 'zh-cn' else "en:1"
        params = {
            'searchTerm': '',
            'activeTerms': f"Language:{language_param},Category:{category['value_id']}",
            'pageNumber': page_number
        }
        
        data = self.get_api_data(config['api_results_url'], params)
        if not data:
            return [], False
        
        downloads = []
        
        # è§£æä¸‹è½½æ•°æ®
        if 'resultPage' in data:
            for result in data['resultPage']:
                # åªå¤„ç†å…¬å¼€çš„æ–‡ä»¶ï¼ˆpublic=trueï¼‰
                if not result.get('public', False):
                    continue
                
                download_url = result.get('downloadUrl', '')
                title = result.get('title', '')
                description = result.get('description', '')
                filetype = result.get('filetype', '')
                filesize = result.get('filesize', '')
                category_name = result.get('category', category['name'])
                modified = result.get('modified', '')
                
                # æ¸…ç†æ–‡ä»¶åï¼šå»æ‰æ–‡ä»¶ç±»å‹å’Œå¤§å°ä¿¡æ¯
                clean_title = title
                if title and ' - ' in title:
                    # ç§»é™¤ " - .PDF, 73 kB" è¿™æ ·çš„åç¼€
                    parts = title.split(' - ')
                    if len(parts) > 1:
                        # æ£€æŸ¥æœ€åä¸€éƒ¨åˆ†æ˜¯å¦åŒ…å«æ–‡ä»¶ç±»å‹å’Œå¤§å°
                        last_part = parts[-1]
                        if any(ext in last_part.upper() for ext in ['.PDF', '.DOC', '.XLS', '.ZIP', 'KB', 'MB']):
                            clean_title = ' - '.join(parts[:-1])
                
                if download_url and title:
                    downloads.append({
                        'url': download_url,
                        'title': clean_title,
                        'original_title': title,
                        'description': description,
                        'filetype': filetype,
                        'filesize': filesize,
                        'category': category_name,
                        'modified': modified,
                        'page': page_number,
                        'website': category['website']
                    })
                    print(f"    æ‰¾åˆ°æ–‡ä»¶: {clean_title}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ›´å¤šé¡µé¢
        has_more = data.get('hasMore', False)
        total_count = data.get('totalCount', 0)
        current_count = len(data.get('resultPage', []))
        
        print(f"  ç¬¬ {page_number} é¡µæ‰¾åˆ° {current_count} ä¸ªæ–‡ä»¶ï¼ˆæ€»è®¡: {total_count}ï¼‰")
        
        return downloads, has_more
    
    def get_all_downloads_by_category(self, category, config):
        """è·å–æŸä¸ªåˆ†ç±»çš„æ‰€æœ‰ä¸‹è½½æ–‡ä»¶ï¼ˆæ”¯æŒåˆ†é¡µï¼‰"""
        # å¯¹äºBrochuresåˆ†ç±»ï¼Œä¼˜å…ˆä½¿ç”¨Seleniumæ»šåŠ¨åŠ è½½
        if category['name'] == 'Brochures' and self.use_selenium:
            self.log(f"å¯¹Brochuresåˆ†ç±»ä½¿ç”¨Seleniumæ»šåŠ¨åŠ è½½...")
            return self.get_downloads_by_category_selenium(category, config)
        
        # å…¶ä»–åˆ†ç±»ä½¿ç”¨ä¼ ç»ŸAPIæ–¹å¼
        all_downloads = []
        page = 1
        
        while True:
            downloads, has_more = self.get_downloads_by_category(category, config, page)
            all_downloads.extend(downloads)
            
            if not has_more or not downloads:
                break
            
            page += 1
            time.sleep(1)  # æ·»åŠ å»¶è¿Ÿé¿å…è¯·æ±‚è¿‡å¿«
        
        print(f"åˆ†ç±» '{category['name']}' å…±æ‰¾åˆ° {len(all_downloads)} ä¸ªæ–‡ä»¶")
        return all_downloads
    
    def download_file(self, download_info):
        """ä¸‹è½½æ–‡ä»¶"""
        try:
            url = download_info['url']
            filename = download_info['title']
            category = download_info['category']
            website = download_info.get('website', 'ä¸­æ–‡ç½‘ç«™')
            
            # æ¸…ç†æ–‡ä»¶åï¼Œç§»é™¤éæ³•å­—ç¬¦
            filename = re.sub(r'[<>:"/\\|?*]', '_', filename)
            
            # å¦‚æœæ–‡ä»¶åä¸ºç©ºæˆ–åªæœ‰ç©ºæ ¼ï¼Œè®¾ç½®é»˜è®¤åç§°
            if not filename or not filename.strip():
                filename = "åº“å¡èµ„æ–™"
            
            # ä»åŸå§‹æ ‡é¢˜æˆ–URLä¸­è·å–æ–‡ä»¶æ‰©å±•å
            ext = ""
            original_title = download_info.get('original_title', '')
            filetype = download_info.get('filetype', '')
            
            # ä¼˜å…ˆä»filetypeè·å–æ‰©å±•å
            if filetype:
                if filetype.startswith('.'):
                    ext = filetype.lower()
                else:
                    ext = f'.{filetype.lower()}'
            else:
                # ä»URLè·å–æ‰©å±•å
                parsed_url = urlparse(url)
                path = parsed_url.path
                if '.' in path:
                    url_ext = '.' + path.split('.')[-1].lower()
                    if url_ext in ['.pdf', '.doc', '.docx', '.xls', '.xlsx', '.zip', '.rar', '.exe', '.dmg', '.msi', '.deb', '.rpm', '.tar', '.gz', '.7z', '.txt', '.rtf', '.ppt', '.pptx', '.csv', '.xml', '.json', '.html', '.htm']:
                        ext = url_ext
            
            # å¦‚æœè¿˜æ˜¯æ²¡æœ‰æ‰©å±•åï¼Œé»˜è®¤ä¸ºPDF
            if not ext:
                ext = '.pdf'
            
            # ç¡®ä¿æ–‡ä»¶åæœ‰æ‰©å±•å
            if not filename.lower().endswith(ext):
                filename += ext
            
            # æ¸…ç†åˆ†ç±»åä¸­çš„éæ³•å­—ç¬¦
            category_clean = re.sub(r'[<>:"/\\|?*]', '_', category)
            
            # åˆ›å»ºç›®å½•ç»“æ„: ç½‘ç«™/åˆ†ç±»/æ–‡ä»¶
            website_dir = os.path.join(self.download_dir, website)
            category_dir = os.path.join(website_dir, category_clean)
            os.makedirs(category_dir, exist_ok=True)
            
            # å®Œæ•´çš„æ–‡ä»¶è·¯å¾„
            filepath = os.path.join(category_dir, filename)
            
            # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½
            if os.path.exists(filepath):
                print(f"        æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡: {filename}")
                return True
            
            print(f"        æ­£åœ¨ä¸‹è½½: {filename}")
            
            # ä½¿ç”¨requestsä¸‹è½½æ–‡ä»¶
            response = self.session.get(url, stream=True, timeout=120)  # å¢åŠ åˆ°120ç§’é€‚åº”å¤§æ–‡ä»¶
            response.raise_for_status()
            
            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            content_length = response.headers.get('content-length')
            if content_length:
                size_mb = int(content_length) / (1024 * 1024)
                if size_mb > 50:  # å¤§äº50MBçš„æ–‡ä»¶ç»™å‡ºæç¤º
                    print(f"        æ–‡ä»¶è¾ƒå¤§ ({size_mb:.1f} MB)ï¼Œä¸‹è½½å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´...")
            
            # æ£€æŸ¥å“åº”å†…å®¹ç±»å‹
            content_type = response.headers.get('content-type', '').lower()
            if 'text/html' in content_type:
                print(f"        è­¦å‘Š: ä¸‹è½½çš„å¯èƒ½ä¸æ˜¯æ–‡ä»¶ï¼Œè€Œæ˜¯HTMLé¡µé¢")
                return False
            
            with open(filepath, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:
                        f.write(chunk)
            
            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            file_size = os.path.getsize(filepath)
            if file_size < 1024:  # å°äº1KBå¯èƒ½æ˜¯é”™è¯¯é¡µé¢
                print(f"        è­¦å‘Š: æ–‡ä»¶å¤§å°å¼‚å¸¸ ({file_size} bytes)")
            
            print(f"        ä¸‹è½½å®Œæˆ: {filename} ({file_size} bytes)")
            
            # è®°å½•æ–°æ–‡ä»¶
            file_key = f"{website}_{category}_{filename}"
            if file_key not in self.processed_files:
                self.new_files.append({
                    'filename': filename,
                    'path': filepath,
                    'url': url,
                    'size': file_size,
                    'category': category,
                    'description': download_info.get('description', ''),
                    'modified': download_info.get('modified', '')
                })
                self.processed_files.add(file_key)
            
            return True
            
        except Exception as e:
            print(f"        ä¸‹è½½å¤±è´¥ {url}: {e}")
            return False
    
    def download_materials(self, downloads, skip_download=False):
        """ä¸‹è½½æ‰€æœ‰æ–‡ä»¶"""
        if not downloads:
            print("æ²¡æœ‰æ–‡ä»¶éœ€è¦ä¸‹è½½")
            return
        
        if skip_download:
            print("è·³è¿‡ä¸‹è½½æ¨¡å¼ï¼Œåªæ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯")
            for download in downloads:
                print(f"æ–‡ä»¶: {download['title']} - {download['category']}")
            return
        
        print(f"\nå¼€å§‹ä¸‹è½½æ–‡ä»¶...")
        print(f"å…±æœ‰ {len(downloads)} ä¸ªæ–‡ä»¶éœ€è¦å¤„ç†")
        
        total_downloads = 0
        successful_downloads = 0
        
        for i, download in enumerate(downloads, 1):
            print(f"\nè¿›åº¦: {i}/{len(downloads)} - {download['category']} - {download['title']}")
            
            total_downloads += 1
            if self.download_file(download):
                successful_downloads += 1
            
            # æ·»åŠ å»¶è¿Ÿé¿å…è¯·æ±‚è¿‡å¿«
            time.sleep(1)
        
        print(f"\næ–‡ä»¶ä¸‹è½½å®Œæˆï¼")
        print(f"æ€»å°è¯•ä¸‹è½½: {total_downloads} ä¸ªæ–‡ä»¶")
        print(f"æˆåŠŸä¸‹è½½: {successful_downloads} ä¸ªæ–‡ä»¶")
        print(f"å¤±è´¥: {total_downloads - successful_downloads} ä¸ªæ–‡ä»¶")
    
    def save_data(self, data, filename):
        """ä¿å­˜æ•°æ®åˆ°æ–‡ä»¶"""
        filepath = os.path.join(self.output_dir, filename)
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            print(f"æ•°æ®å·²ä¿å­˜åˆ°: {filepath}")
        except Exception as e:
            print(f"ä¿å­˜æ•°æ®å¤±è´¥: {e}")
    
    def run(self, limit=None, skip_download=False, target_categories=None, target_websites=None):
        """è¿è¡Œçˆ¬è™«"""
        self.log("ğŸš€ å¼€å§‹çˆ¬å–åº“å¡ä¸‹è½½ä¸­å¿ƒ...")
        
        # ç¡®å®šè¦çˆ¬å–çš„ç½‘ç«™
        websites_to_crawl = []
        if target_websites:
            if 'ä¸­æ–‡' in target_websites or 'cn' in target_websites:
                websites_to_crawl.append(self.cn_config)
            if 'è‹±æ–‡' in target_websites or 'en' in target_websites:
                websites_to_crawl.append(self.en_config)
        else:
            # é»˜è®¤çˆ¬å–ä¸¤ä¸ªç½‘ç«™
            websites_to_crawl = [self.cn_config, self.en_config]
        
        all_categories = []
        
        # 1. è·å–æ‰€æœ‰ç½‘ç«™çš„åˆ†ç±»
        for config in websites_to_crawl:
            categories = self.get_categories(config)
            if categories:
                all_categories.extend(categories)
            else:
                self.log(f"âŒ {config['folder_name']}æœªæ‰¾åˆ°ä»»ä½•åˆ†ç±»")
        
        if not all_categories:
            self.log("âŒ æœªæ‰¾åˆ°ä»»ä½•åˆ†ç±»")
            return
        
        # å¦‚æœæŒ‡å®šäº†ç‰¹å®šåˆ†ç±»ï¼Œåªå¤„ç†è¿™äº›åˆ†ç±»
        if target_categories:
            filtered_categories = []
            for cat in all_categories:
                if cat['name'] in target_categories:
                    filtered_categories.append(cat)
            all_categories = filtered_categories
            if not all_categories:
                self.log(f"âŒ æœªæ‰¾åˆ°æŒ‡å®šçš„åˆ†ç±»: {target_categories}")
                return
            self.log(f"ğŸ“‹ ç­›é€‰åå…± {len(all_categories)} ä¸ªåˆ†ç±»: {[cat['website'] + '-' + cat['name'] for cat in all_categories]}")
        else:
            self.log(f"ğŸ“‹ å…±æ‰¾åˆ° {len(all_categories)} ä¸ªåˆ†ç±»")
        
        # 2. ä¿å­˜åˆ†ç±»ä¿¡æ¯
        self.save_data(all_categories, 'categories.json')
        
        # 3. çˆ¬å–æ¯ä¸ªåˆ†ç±»çš„æ–‡ä»¶
        all_downloads = []
        for i, category in enumerate(all_categories, 1):
            self.log(f"ğŸ”„ è¿›åº¦: {i}/{len(all_categories)} - {category['website']}-{category['name']}")
            
            # æ‰¾åˆ°å¯¹åº”çš„ç½‘ç«™é…ç½®
            config = self.cn_config if category['website'] == 'ä¸­æ–‡ç½‘ç«™' else self.en_config
            downloads = self.get_all_downloads_by_category(category, config)
            all_downloads.extend(downloads)
            
            # å¦‚æœè®¾ç½®äº†é™åˆ¶ï¼Œæ£€æŸ¥æ˜¯å¦è¾¾åˆ°é™åˆ¶
            if limit and len(all_downloads) >= limit:
                all_downloads = all_downloads[:limit]
                self.log(f"âš ï¸ è¾¾åˆ°é™åˆ¶æ•°é‡ {limit}ï¼Œåœæ­¢çˆ¬å–")
                break
            
            # æ·»åŠ å»¶è¿Ÿé¿å…è¯·æ±‚è¿‡å¿«
            time.sleep(2)
        
        # 4. ä¿å­˜æ‰€æœ‰æ–‡ä»¶ä¿¡æ¯
        if all_downloads:
            self.save_data(all_downloads, 'downloads.json')
            self.log(f"âœ… çˆ¬å–å®Œæˆï¼å…±è·å– {len(all_downloads)} ä¸ªæ–‡ä»¶")
        else:
            self.log("âŒ æœªæ‰¾åˆ°ä»»ä½•æ–‡ä»¶")
            return
        
        # 5. ä¸‹è½½æ–‡ä»¶
        self.download_materials(all_downloads, skip_download)
        
        # 6. ä¿å­˜å¤„ç†è®°å½•
        if not skip_download:
            self.save_processed_files()
        
        # 7. å‘é€é’‰é’‰é€šçŸ¥
        if not skip_download:
            self.send_completion_notification()
        
        # 8. ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
        self.generate_report(all_categories, all_downloads)
    
    def send_completion_notification(self):
        """å‘é€å®Œæˆé€šçŸ¥"""
        if not self.new_files:
            if not self.is_first_run:
                self.log("ğŸ“¢ æ— æ–°æ–‡ä»¶ï¼Œä¸å‘é€é€šçŸ¥")
            return
        
        # æ„å»ºé€šçŸ¥æ¶ˆæ¯
        message_parts = []
        message_parts.append(f"ğŸ“Š åº“å¡çˆ¬è™«å®Œæˆ")
        message_parts.append(f"ğŸ•’ æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        message_parts.append(f"ğŸ“ æ–°ä¸‹è½½æ–‡ä»¶: {len(self.new_files)} ä¸ª")
        
        if self.is_first_run:
            message_parts.append("ğŸ†• é¦–æ¬¡è¿è¡Œï¼Œå·²å»ºç«‹åŸºçº¿")
        
        # æŒ‰åˆ†ç±»åˆ†ç»„æ˜¾ç¤ºæ–°æ–‡ä»¶
        category_files = {}
        for file_info in self.new_files:
            category = file_info['category']
            if category not in category_files:
                category_files[category] = []
            category_files[category].append(file_info)
        
        message_parts.append("\nğŸ“‹ æ–°æ–‡ä»¶è¯¦æƒ…:")
        for category, files in category_files.items():
            message_parts.append(f"  ğŸ“‚ {category}: {len(files)} ä¸ªæ–‡ä»¶")
            for file_info in files[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                size_mb = file_info['size'] / 1024 / 1024
                message_parts.append(f"    ğŸ“„ {file_info['filename']} ({size_mb:.1f}MB)")
            if len(files) > 3:
                message_parts.append(f"    ... è¿˜æœ‰ {len(files) - 3} ä¸ªæ–‡ä»¶")
        
        message = "\n".join(message_parts)
        self.send_dingtalk_notification(message)
    
    def generate_report(self, categories, downloads):
        """ç”Ÿæˆçˆ¬å–æŠ¥å‘Š"""
        report = {
            'çˆ¬å–æ—¶é—´': time.strftime('%Y-%m-%d %H:%M:%S'),
            'æ€»åˆ†ç±»æ•°': len(categories),
            'æ€»æ–‡ä»¶æ•°': len(downloads),
            'åˆ†ç±»åˆ—è¡¨': [c['name'] for c in categories],
            'å„åˆ†ç±»æ–‡ä»¶æ•°é‡': {},
            'è·³è¿‡çš„åˆ†ç±»': self.skip_categories,
            'ä½¿ç”¨Selenium': self.use_selenium
        }
        
        # ç»Ÿè®¡å„åˆ†ç±»æ–‡ä»¶æ•°é‡
        for category in categories:
            category_downloads = [d for d in downloads if d['category'] == category['name']]
            report['å„åˆ†ç±»æ–‡ä»¶æ•°é‡'][category['name']] = len(category_downloads)
        
        # ä¿å­˜æŠ¥å‘Š
        self.save_data(report, 'çˆ¬å–æŠ¥å‘Š.json')
        
        # æ‰“å°æŠ¥å‘Š
        print("\n" + "="*50)
        print("åº“å¡ä¸‹è½½ä¸­å¿ƒçˆ¬å–æŠ¥å‘Š")
        print("="*50)
        print(f"çˆ¬å–æ—¶é—´: {report['çˆ¬å–æ—¶é—´']}")
        print(f"æ€»åˆ†ç±»æ•°: {report['æ€»åˆ†ç±»æ•°']}")
        print(f"æ€»æ–‡ä»¶æ•°: {report['æ€»æ–‡ä»¶æ•°']}")
        print(f"è·³è¿‡åˆ†ç±»: {', '.join(report['è·³è¿‡çš„åˆ†ç±»'])}")
        print(f"ä½¿ç”¨Selenium: {'æ˜¯' if report['ä½¿ç”¨Selenium'] else 'å¦'}")
        print("\nå„åˆ†ç±»æ–‡ä»¶æ•°é‡:")
        for category_name, count in report['å„åˆ†ç±»æ–‡ä»¶æ•°é‡'].items():
            print(f"  {category_name}: {count} ä¸ª")
        
        print("="*50)
    
    def download_materials_only(self):
        """åªä¸‹è½½æ–‡ä»¶ï¼Œä¸é‡æ–°çˆ¬å–æ–‡ä»¶ä¿¡æ¯"""
        print("å¼€å§‹ä¸‹è½½æ–‡ä»¶ï¼ˆä½¿ç”¨ç°æœ‰æ–‡ä»¶æ•°æ®ï¼‰...")
        
        # åŠ è½½ç°æœ‰æ–‡ä»¶æ•°æ®
        downloads_file = os.path.join(self.output_dir, 'downloads.json')
        if not os.path.exists(downloads_file):
            print("æœªæ‰¾åˆ°æ–‡ä»¶æ•°æ®ï¼Œè¯·å…ˆè¿è¡Œå®Œæ•´çˆ¬å–")
            return
        
        try:
            with open(downloads_file, 'r', encoding='utf-8') as f:
                downloads = json.load(f)
            
            print(f"åŠ è½½äº† {len(downloads)} ä¸ªæ–‡ä»¶ä¿¡æ¯")
            self.download_materials(downloads)
            
        except Exception as e:
            print(f"åŠ è½½æ–‡ä»¶æ•°æ®å¤±è´¥: {e}")
    
    def get_manuals(self, config):
        """è·å–æ‰‹å†Œæ–‡ä»¶ï¼ˆåŒ…æ‹¬Brochuresã€æ‰‹å†Œç­‰åˆ†ç±»ï¼‰"""
        self.log(f"å¼€å§‹è·å–æ‰‹å†Œæ–‡ä»¶...")
        
        # è·å–æ‰€æœ‰åˆ†ç±»
        categories = self.get_categories(config)
        
        # å®šä¹‰æ‰‹å†Œç›¸å…³çš„åˆ†ç±»åç§°
        manual_keywords = ['æ‰‹å†Œ', 'Brochures', 'brochure', 'manual', 'Manual', 'Manuals']
        
        manual_downloads = []
        
        for category in categories:
            category_name = category['name']
            
            # æ£€æŸ¥åˆ†ç±»åç§°æ˜¯å¦åŒ…å«æ‰‹å†Œç›¸å…³å…³é”®è¯
            is_manual_category = any(keyword in category_name for keyword in manual_keywords)
            
            if is_manual_category:
                self.log(f"æ‰¾åˆ°æ‰‹å†Œåˆ†ç±»: {category_name} ({category['count']} ä¸ªæ–‡ä»¶)")
                
                # è·å–è¯¥åˆ†ç±»çš„æ‰€æœ‰æ–‡ä»¶
                downloads = self.get_all_downloads_by_category(category, config)
                
                # ä¸ºæ¯ä¸ªæ–‡ä»¶æ·»åŠ åˆ†ç±»ä¿¡æ¯
                for download in downloads:
                    download['category'] = category_name
                
                manual_downloads.extend(downloads)
                self.log(f"ä»åˆ†ç±» '{category_name}' è·å–åˆ° {len(downloads)} ä¸ªæ–‡ä»¶")
        
        self.log(f"æ€»å…±è·å–åˆ° {len(manual_downloads)} ä¸ªæ‰‹å†Œæ–‡ä»¶")
        return manual_downloads

if __name__ == "__main__":
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description='åº“å¡ä¸‹è½½ä¸­å¿ƒçˆ¬è™«')
    parser.add_argument('--download-only', action='store_true', help='åªä¸‹è½½æ–‡ä»¶ï¼Œä¸é‡æ–°çˆ¬å–')
    parser.add_argument('--limit', type=int, help='é™åˆ¶çˆ¬å–çš„æ–‡ä»¶æ•°é‡ï¼ˆç”¨äºæµ‹è¯•ï¼‰')
    parser.add_argument('--skip-download', action='store_true', help='è·³è¿‡ä¸‹è½½ï¼Œåªçˆ¬å–æ–‡ä»¶ä¿¡æ¯')
    parser.add_argument('--categories', nargs='+', help='æŒ‡å®šè¦çˆ¬å–çš„åˆ†ç±»åç§°ï¼ˆå¯å¤šä¸ªï¼‰')
    parser.add_argument('--websites', nargs='+', choices=['ä¸­æ–‡', 'è‹±æ–‡', 'cn', 'en'], help='æŒ‡å®šè¦çˆ¬å–çš„ç½‘ç«™ï¼ˆä¸­æ–‡/è‹±æ–‡ï¼‰')
    parser.add_argument('--no-selenium', action='store_true', help='ç¦ç”¨Seleniumï¼Œä½¿ç”¨ä¼ ç»ŸAPIæ–¹å¼')
    
    args = parser.parse_args()
    
    spider = KukaSpider()
    
    # å¦‚æœæŒ‡å®šäº†ç¦ç”¨Selenium
    if args.no_selenium:
        spider.use_selenium = False
        print("å·²ç¦ç”¨Seleniumï¼Œå°†ä½¿ç”¨ä¼ ç»ŸAPIæ–¹å¼")
    
    try:
        if args.download_only:
            spider.download_materials_only()
        else:
            spider.run(limit=args.limit, skip_download=args.skip_download, target_categories=args.categories, target_websites=args.websites)
    except KeyboardInterrupt:
        print("\nç”¨æˆ·ä¸­æ–­çˆ¬å–")
    except Exception as e:
        print(f"çˆ¬å–è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
