#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import time
import json
import pickle
import platform
import re
from datetime import datetime
from pathlib import Path
from urllib.parse import urljoin, urlparse, unquote
import requests
import chardet
import hmac
import base64
import hashlib
import urllib.parse
import shutil

# Selenium imports
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.common.exceptions import TimeoutException, NoSuchElementException, ElementClickInterceptedException
from bs4 import BeautifulSoup

class TengenSpider:
    def __init__(self):
        # åŸºç¡€é…ç½®
        self.base_url = "https://www.tengen.com"
        self.download_api_base = "https://dmc.tengen.com.cn/xweb/api/v1/dms/commonAttachUpload/getFile"
        self.detail_base = "https://zx.tengen.com.cn/#/details"
        
        # æœåŠ¡å™¨å›ºå®šè·¯å¾„ï¼ˆæŒ‰è§„èŒƒè¦æ±‚ï¼‰ï¼Œæœ¬åœ°æµ‹è¯•ä½¿ç”¨å½“å‰ç›®å½•
        if os.path.exists("/srv/downloads/approved/"):
            self.base_dir = "/srv/downloads/approved/å¤©æ­£"
        else:
            # æœ¬åœ°æµ‹è¯•ç¯å¢ƒ
            self.base_dir = os.path.join(os.getcwd(), "downloads", "å¤©æ­£")
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(self.base_dir, exist_ok=True)
        
        # è®¾ç½®ä¸‹è½½æ–‡ä»¶å¤¹ï¼ˆä¸base_dirç›¸åŒï¼‰
        self.download_folder = self.base_dir
        
        self.processed_urls = self.load_processed_urls()
        self.new_files = []
        self.debug = True
        
        # åˆ¤æ–­æ˜¯å¦ä¸ºé¦–æ¬¡è¿è¡Œï¼ˆå…¨é‡çˆ¬å–ï¼‰
        self.is_first_run = not os.path.exists(os.path.join(self.base_dir, 'processed_urls.pkl'))
        
        # é’‰é’‰é€šçŸ¥é…ç½®
        self.ACCESS_TOKEN = "1a431b6482e59ec652a6eab37705d50fd282dc426f0b829b3eb9a9c1b277ed24"
        self.SECRET = "SECc5e2168011dd97d4c511e06832d172f31635ef635771668e4e6003fce23c07bb"
        
        # åˆå§‹åŒ–WebDriver
        self.driver = None
        self.init_webdriver()
        
        # å¤©æ­£ç½‘ç«™çš„ä¸»è¦åˆ†ç±» - åªçˆ¬å–æ§åˆ¶ç”µå™¨æ¨¡å—
        self.main_categories = [
            {'name': 'æ§åˆ¶ç”µå™¨', 'url': 'https://www.tengen.com/controlelectrics.html'}
        ]
        
        # æ–‡æ¡£åˆ†ç±»æ˜ å°„ - å»é™¤å•†å“ä»‹ç»
        self.doc_categories = {
            'å•†å“å‚æ•°': 'å•†å“å‚æ•°', 
            'äº§å“æ ·æœ¬': 'äº§å“æ ·æœ¬',
            'æ£€æµ‹æŠ¥å‘Š': 'æ£€æµ‹æŠ¥å‘Š',
            'è®¤è¯è¯ä¹¦': 'è®¤è¯è¯ä¹¦'
        }
        
        # æ§åˆ¶ç”µå™¨çš„å­åˆ†ç±» - åªçˆ¬å–é«˜å‹äº¤æµçœŸç©ºæ–­æµå™¨
        self.control_subcategories = [
            {'name': 'é«˜å‹äº¤æµçœŸç©ºæ–­æµå™¨', 'url': 'https://www.tengen.com/gaoyawuwaiduanluqi.html'}
        ]
        
    def init_webdriver(self):
        """åˆå§‹åŒ–Chrome WebDriver"""
        try:
            # æ£€æµ‹ç³»ç»Ÿæ¶æ„
            system = platform.system()
            machine = platform.machine()
            
            # ç¡®å®šchromedriverè·¯å¾„
            # åœ¨æœåŠ¡å™¨ä¸ŠæŸ¥æ‰¾chromedriverç›®å½•
            if os.path.exists("/srv/crawler/chromedriver_downloads"):
                chromedriver_dir = "/srv/crawler/chromedriver_downloads"
            else:
                chromedriver_dir = os.path.join(os.getcwd(), "chromedriver_downloads")
            
            if system == "Darwin":  # macOS
                if machine == "arm64":
                    chromedriver_path = os.path.join(chromedriver_dir, "chromedriver_mac-arm64", "chromedriver-mac-arm64", "chromedriver")
                else:
                    chromedriver_path = os.path.join(chromedriver_dir, "chromedriver_mac-x64", "chromedriver-mac-x64", "chromedriver")
            elif system == "Linux":
                chromedriver_path = os.path.join(chromedriver_dir, "chromedriver_linux64", "chromedriver-linux64", "chromedriver")
            elif system == "Windows":
                chromedriver_path = os.path.join(chromedriver_dir, "chromedriver_win64", "chromedriver-win64", "chromedriver.exe")
            else:
                raise Exception(f"ä¸æ”¯æŒçš„æ“ä½œç³»ç»Ÿ: {system}")
            
            if not os.path.exists(chromedriver_path):
                raise Exception(f"ChromeDriveræœªæ‰¾åˆ°: {chromedriver_path}")
            
            # è®¾ç½®Chromeé€‰é¡¹
            chrome_options = Options()
            chrome_options.add_argument('--headless')  # æ— å¤´æ¨¡å¼
            chrome_options.add_argument('--no-sandbox')
            chrome_options.add_argument('--disable-dev-shm-usage')
            chrome_options.add_argument('--disable-gpu')
            chrome_options.add_argument('--window-size=1920,1080')
            chrome_options.add_argument('--user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
            
            # é…ç½®ä¸‹è½½è®¾ç½®
            download_dir = os.path.expanduser("~/Downloads")
            prefs = {
                "download.default_directory": download_dir,
                "download.prompt_for_download": False,
                "download.directory_upgrade": True,
                "safebrowsing.enabled": True
            }
            chrome_options.add_experimental_option("prefs", prefs)
            
            # å¯ç”¨æ—¥å¿—è®°å½•ä»¥ç›‘æ§ç½‘ç»œè¯·æ±‚
            chrome_options.add_experimental_option('perfLoggingPrefs', {'enableNetwork': True})
            chrome_options.add_experimental_option('useAutomationExtension', False)
            chrome_options.set_capability('goog:loggingPrefs', {'performance': 'ALL'})
            
            # åˆå§‹åŒ–WebDriver
            service = Service(executable_path=chromedriver_path)
            self.driver = webdriver.Chrome(service=service, options=chrome_options)
            self.driver.implicitly_wait(10)
            
            self.log("âœ… Chrome WebDriveråˆå§‹åŒ–æˆåŠŸ")
            
        except Exception as e:
            self.log(f"âŒ WebDriveråˆå§‹åŒ–å¤±è´¥: {str(e)}")
            raise
    
    def log(self, message):
        """æ—¥å¿—è®°å½•"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        print(f"[{timestamp}] {message}")
    
    def monitor_network_requests(self, duration=5):
        """ç›‘æ§ç½‘ç»œè¯·æ±‚ï¼Œæ•è·ä¸‹è½½é“¾æ¥"""
        download_urls = []
        try:
            # è·å–æ€§èƒ½æ—¥å¿—
            logs = self.driver.get_log('performance')
            
            for log_entry in logs:
                message = json.loads(log_entry['message'])
                
                # æ£€æŸ¥å“åº”äº‹ä»¶
                if message['message']['method'] == 'Network.responseReceived':
                    response = message['message']['params']['response']
                    url = response['url']
                    
                    # æ£€æŸ¥æ˜¯å¦ä¸ºä¸‹è½½æ–‡ä»¶
                    if self.is_download_url(url):
                        # æ£€æŸ¥Content-Type
                        headers = response.get('headers', {})
                        content_type = headers.get('content-type', '').lower()
                        
                        # æ–‡æ¡£ç±»å‹çš„Content-Type
                        download_content_types = [
                            'application/pdf',
                            'application/msword',
                            'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
                            'application/vnd.ms-excel',
                            'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
                            'application/zip',
                            'application/x-rar-compressed',
                            'application/octet-stream'
                        ]
                        
                        if any(ct in content_type for ct in download_content_types) or url.endswith(('.pdf', '.doc', '.docx', '.xls', '.xlsx', '.zip', '.rar')):
                            download_urls.append(url)
                            self.log(f"   ğŸ¯ ç½‘ç»œç›‘æ§æ•è·ä¸‹è½½é“¾æ¥: {url}")
        
        except Exception as e:
            self.log(f"   âš ï¸ ç½‘ç»œç›‘æ§å¤±è´¥: {str(e)}")
        
        return download_urls
    
    def is_download_url(self, url):
        """åˆ¤æ–­URLæ˜¯å¦ä¸ºä¸‹è½½é“¾æ¥"""
        if not url:
            return False
            
        download_indicators = [
            'dmc.tengen.com.cn',
            'download',
            'file',
            'getFile',
            '.pdf',
            '.doc',
            '.docx',
            '.xls',
            '.xlsx',
            '.zip',
            '.rar'
        ]
        
        url_lower = url.lower()
        return any(indicator in url_lower for indicator in download_indicators)
    
    def load_processed_urls(self):
        """åŠ è½½å·²å¤„ç†çš„URLåˆ—è¡¨"""
        processed_file = os.path.join(self.base_dir, 'processed_urls.pkl')
        if os.path.exists(processed_file):
            try:
                with open(processed_file, 'rb') as f:
                    return pickle.load(f)
            except:
                return set()
        return set()
    
    def save_processed_urls(self):
        """ä¿å­˜å·²å¤„ç†çš„URLåˆ—è¡¨"""
        processed_file = os.path.join(self.base_dir, 'processed_urls.pkl')
        with open(processed_file, 'wb') as f:
            pickle.dump(self.processed_urls, f)
    
    def visit_page(self, url, retry_count=3):
        """è®¿é—®é¡µé¢å¹¶è¿”å›BeautifulSoupå¯¹è±¡"""
        for attempt in range(retry_count):
            try:
                self.log(f"ğŸ”„ è®¿é—®é¡µé¢ (å°è¯•{attempt+1}/{retry_count}): {url}")
                self.driver.get(url)
                
                # ç­‰å¾…é¡µé¢åŠ è½½å®Œæˆ
                WebDriverWait(self.driver, 30).until(
                    lambda driver: driver.execute_script("return document.readyState") == "complete"
                )
                
                # é¢å¤–ç­‰å¾…JavaScriptæ‰§è¡Œ
                time.sleep(3)
                
                # å°è¯•æ»šåŠ¨é¡µé¢åŠ è½½æ›´å¤šå†…å®¹
                self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                time.sleep(2)
                
                # è·å–é¡µé¢æºç 
                page_source = self.driver.page_source
                soup = BeautifulSoup(page_source, 'html.parser')
                
                return soup
                
            except Exception as e:
                self.log(f"âŒ é¡µé¢è®¿é—®å¤±è´¥ (å°è¯•{attempt+1}): {str(e)}")
                time.sleep(5)
        
        self.log(f"âŒ é¡µé¢è®¿é—®å®Œå…¨å¤±è´¥: {url}")
        return None

    def find_subcategories(self, soup, category_name):
        """æŸ¥æ‰¾å­åˆ†ç±» - åªçˆ¬å–ç»§ç”µå™¨å’Œæ¥è§¦å™¨"""
        subcategories = []
        
        try:
            # åªè¿”å›é¢„å®šä¹‰çš„ç»§ç”µå™¨å’Œæ¥è§¦å™¨å­åˆ†ç±»
            if category_name == 'æ§åˆ¶ç”µå™¨':
                subcategories = self.control_subcategories
                self.log(f"âœ… ä½¿ç”¨é¢„å®šä¹‰çš„æ§åˆ¶ç”µå™¨å­åˆ†ç±»: {[sub['name'] for sub in subcategories]}")
            else:
                self.log(f"âš ï¸ éæ§åˆ¶ç”µå™¨åˆ†ç±»: {category_name}")
            
            self.log(f"ğŸ” åœ¨ {category_name} ä¸­æ‰¾åˆ° {len(subcategories)} ä¸ªå­åˆ†ç±»")
            
        except Exception as e:
            self.log(f"âŒ æŸ¥æ‰¾å­åˆ†ç±»æ—¶å‡ºé”™: {str(e)}")
        
        return subcategories

    def find_products(self, soup, subcategory_name):
        """æŸ¥æ‰¾äº§å“åˆ—è¡¨ - åªçˆ¬å–æŒ‡å®šçš„é«˜å‹äº¤æµçœŸç©ºæ–­æµå™¨äº§å“"""
        products = []
        
        try:
            # æŸ¥æ‰¾æ‰€æœ‰äº§å“é“¾æ¥ g-proList-r-con
            product_links = soup.find_all('a', class_='g-proList-r-con', href=True)
            
            if not product_links:
                self.log(f"   âš ï¸ æœªæ‰¾åˆ°g-proList-r-conäº§å“é“¾æ¥")
                return products
            
            self.log(f"   âœ… æ‰¾åˆ° {len(product_links)} ä¸ªäº§å“é“¾æ¥")
            
            for link in product_links:
                href = link.get('href', '')
                
                # ä»h3æ ‡ç­¾è·å–äº§å“åç§°
                h3_tag = link.find('h3', class_='g-font18')
                if h3_tag:
                    text = h3_tag.get_text().strip()
                else:
                    text = link.get_text().strip()
                
                if text and href:
                    # æ„å»ºå®Œæ•´URL
                    if href.startswith('/'):
                        full_url = urljoin(self.base_url, href)
                    elif not href.startswith('http'):
                        full_url = urljoin(self.base_url, href)
                    else:
                        full_url = href
                    
                    products.append({
                        'name': text,
                        'url': full_url,
                        'box_type': 'é«˜å‹äº¤æµçœŸç©ºæ–­æµå™¨'  # å›ºå®šå®¹å™¨ç±»å‹
                    })
                    self.log(f"   âœ… æ‰¾åˆ°é«˜å‹äº¤æµçœŸç©ºæ–­æµå™¨äº§å“: {text} -> {href}")
            
            self.log(f"ğŸ” åœ¨ {subcategory_name} ä¸­æ‰¾åˆ° {len(products)} ä¸ªäº§å“")
            
        except Exception as e:
            self.log(f"âŒ æŸ¥æ‰¾äº§å“æ—¶å‡ºé”™: {str(e)}")
        
        return products

    def extract_product_id_from_url(self, url):
        """ä»äº§å“URLä¸­æå–äº§å“ID"""
        try:
            # ä»URLä¸­æå–äº§å“IDï¼Œé€šå¸¸åœ¨è·¯å¾„å‚æ•°ä¸­
            if 'appurl' in url:
                # ä»ç±»ä¼¼ /ACB/appurl123.html çš„URLä¸­æå–æ•°å­—ID
                match = re.search(r'appurl(\d+)', url)
                if match:
                    return match.group(1)
            
            # å…¶ä»–å¯èƒ½çš„IDæå–æ¨¡å¼
            match = re.search(r'/(\d+)\.html', url)
            if match:
                return match.group(1)
                
            return None
            
        except Exception as e:
            self.log(f"âš ï¸ æå–äº§å“IDå¤±è´¥: {str(e)}")
            return None

    def get_product_detail_url(self, product_url):
        """è·å–äº§å“è¯¦æƒ…é¡µURLï¼ˆå•†åŸé¡µé¢ï¼‰"""
        try:
            # è®¿é—®äº§å“é¡µé¢è·å–è¯¦æƒ…é“¾æ¥
            soup = self.visit_page(product_url)
            if not soup:
                return None
            
            # æ–¹æ³•1: æŸ¥æ‰¾"æ ·æœ¬ä¸‹è½½"æˆ–"è¯ä¹¦ä¸‹è½½"ç­‰ä¸‹è½½ç›¸å…³é“¾æ¥
            download_links = soup.find_all('a', href=True, string=lambda text: text and any(
                keyword in text for keyword in ['æ ·æœ¬ä¸‹è½½', 'è¯ä¹¦ä¸‹è½½', 'èµ„æ–™ä¸‹è½½', 'ä¸‹è½½', 'è¯¦æƒ…']
            ))
            
            for link in download_links:
                href = link.get('href', '')
                if 'zx.tengen.com.cn' in href:
                    self.log(f"   âœ… æ‰¾åˆ°è¯¦æƒ…é¡µé“¾æ¥: {href}")
                    return href
            
            # æ–¹æ³•2: æŸ¥æ‰¾æ‰€æœ‰åŒ…å«zx.tengen.com.cnçš„é“¾æ¥
            all_links = soup.find_all('a', href=lambda href: href and 'zx.tengen.com.cn' in href)
            if all_links:
                href = all_links[0].get('href', '')
                self.log(f"   âœ… æ‰¾åˆ°å•†åŸé“¾æ¥: {href}")
                return href
            
            # æ–¹æ³•3: å¦‚æœæ²¡æ‰¾åˆ°ç›´æ¥é“¾æ¥ï¼Œå°è¯•ä»äº§å“IDæ„å»º
            product_id = self.extract_product_id_from_url(product_url)
            if product_id:
                detail_url = f"https://zx.tengen.com.cn/#/details?unique={product_id}&tabIndex=0"
                self.log(f"   âœ… æ„å»ºè¯¦æƒ…é¡µé“¾æ¥: {detail_url}")
                return detail_url
            
            # æ–¹æ³•4: ç‰¹æ®Šå¤„ç†ï¼Œå¦‚æœæ˜¯å·²çŸ¥çš„äº§å“URLæ¨¡å¼
            if 'ACB/appurl123.html' in product_url:
                # è¿™æ˜¯ç”¨æˆ·ç¤ºä¾‹ä¸­çš„URLï¼Œç›´æ¥æ„å»ºå¯¹åº”çš„è¯¦æƒ…é¡µ
                detail_url = "https://zx.tengen.com.cn/#/details?unique=330011203999&tabIndex=0"
                self.log(f"   âœ… ä½¿ç”¨ç¤ºä¾‹è¯¦æƒ…é¡µé“¾æ¥: {detail_url}")
                return detail_url
            
            self.log(f"âŒ æ— æ³•è·å–è¯¦æƒ…é¡µURL: {product_url}")
            return None
            
        except Exception as e:
            self.log(f"âŒ è·å–äº§å“è¯¦æƒ…é¡µURLå¤±è´¥: {str(e)}")
            return None

    def save_product_screenshot(self, category_name=None, subcategory_name=None, product_name=None):
        """ä¿å­˜äº§å“è¯¦æƒ…é¡µæˆªå›¾"""
        try:
            # åˆ›å»ºæˆªå›¾ç›®å½•
            screenshots_dir = os.path.join(self.base_dir, "screenshots")
            if category_name:
                screenshots_dir = os.path.join(screenshots_dir, self.clean_filename(category_name))
            if subcategory_name:
                screenshots_dir = os.path.join(screenshots_dir, self.clean_filename(subcategory_name))
            if product_name:
                screenshots_dir = os.path.join(screenshots_dir, self.clean_filename(product_name))
            
            os.makedirs(screenshots_dir, exist_ok=True)
            
            # ç”Ÿæˆæˆªå›¾æ–‡ä»¶å
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            screenshot_filename = f"product_detail_{timestamp}.png"
            screenshot_path = os.path.join(screenshots_dir, screenshot_filename)
            
            # æˆªå›¾
            self.driver.save_screenshot(screenshot_path)
            self.log(f"ğŸ“¸ äº§å“è¯¦æƒ…é¡µæˆªå›¾å·²ä¿å­˜: {screenshot_path}")
            
            return screenshot_path
            
        except Exception as e:
            self.log(f"âŒ ä¿å­˜æˆªå›¾å¤±è´¥: {str(e)}")
            return None

    def save_tab_screenshot(self, category_name=None, subcategory_name=None, product_name=None, tab_name=None):
        """ä¿å­˜æ ‡ç­¾é¡µæˆªå›¾"""
        try:
            # åˆ›å»ºæˆªå›¾ç›®å½•
            screenshots_dir = os.path.join(self.base_dir, "screenshots")
            if category_name:
                screenshots_dir = os.path.join(screenshots_dir, self.clean_filename(category_name))
            if subcategory_name:
                screenshots_dir = os.path.join(screenshots_dir, self.clean_filename(subcategory_name))
            if product_name:
                screenshots_dir = os.path.join(screenshots_dir, self.clean_filename(product_name))
            
            os.makedirs(screenshots_dir, exist_ok=True)
            
            # ç”Ÿæˆæˆªå›¾æ–‡ä»¶å
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            tab_filename = self.clean_filename(tab_name) if tab_name else "unknown_tab"
            screenshot_filename = f"{tab_filename}_{timestamp}.png"
            screenshot_path = os.path.join(screenshots_dir, screenshot_filename)
            
            # æˆªå›¾
            self.driver.save_screenshot(screenshot_path)
            self.log(f"ğŸ“¸ {tab_name} æ ‡ç­¾é¡µæˆªå›¾å·²ä¿å­˜: {screenshot_path}")
            
            return screenshot_path
            
        except Exception as e:
            self.log(f"âŒ ä¿å­˜ {tab_name} æ ‡ç­¾é¡µæˆªå›¾å¤±è´¥: {str(e)}")
            return None

    def switch_to_product_detail_tabs(self, detail_url, category_name=None, subcategory_name=None, product_name=None):
        """åˆ‡æ¢åˆ°äº§å“è¯¦æƒ…é¡µçš„å„ä¸ªæ ‡ç­¾é¡µå¹¶è·å–ä¸‹è½½ä¿¡æ¯"""
        downloads = []
        
        try:
            self.log(f"ğŸ” è®¿é—®äº§å“è¯¦æƒ…é¡µ: {detail_url}")
            self.driver.get(detail_url)
            
            # ç­‰å¾…é¡µé¢åŠ è½½
            time.sleep(5)
            
            # ä¿å­˜äº§å“è¯¦æƒ…é¡µæˆªå›¾
            self.save_product_screenshot(category_name, subcategory_name, product_name)
            
            # è°ƒè¯•ï¼šè¾“å‡ºé¡µé¢ä¸Šçš„æ ‡ç­¾é¡µç»“æ„
            try:
                page_source = self.driver.page_source
                soup = BeautifulSoup(page_source, 'html.parser')
                
                # æŸ¥æ‰¾æ‰€æœ‰å¯èƒ½çš„æ ‡ç­¾é¡µç»“æ„
                tab_containers = []
                tab_containers.extend(soup.find_all('ul', class_=lambda x: x and 'tab' in x.lower()))
                tab_containers.extend(soup.find_all('div', class_=lambda x: x and 'tab' in x.lower()))
                
                self.log(f"ğŸ” è°ƒè¯•ï¼šæ‰¾åˆ° {len(tab_containers)} ä¸ªå¯èƒ½çš„æ ‡ç­¾é¡µå®¹å™¨")
                for i, container in enumerate(tab_containers[:3]):  # åªæ˜¾ç¤ºå‰3ä¸ª
                    self.log(f"   å®¹å™¨{i+1}: {container.name} class='{container.get('class', '')}'")
                    tabs = container.find_all(['li', 'div', 'span'])
                    for j, tab in enumerate(tabs[:6]):  # æ¯ä¸ªå®¹å™¨åªæ˜¾ç¤ºå‰6ä¸ªæ ‡ç­¾
                        text = tab.get_text().strip()
                        if text and len(text) < 20:  # è¿‡æ»¤æ‰è¿‡é•¿çš„æ–‡æœ¬
                            self.log(f"     æ ‡ç­¾{j+1}: '{text}'")
            except Exception as debug_e:
                self.log(f"ğŸ” è°ƒè¯•ä¿¡æ¯è·å–å¤±è´¥: {str(debug_e)}")
            
            # å®šä¹‰æ ‡ç­¾é¡µæ˜ å°„ - å»é™¤å•†å“ä»‹ç»
            tabs = {
                'å•†å“å‚æ•°': 1,
                'äº§å“æ ·æœ¬': 2,
                'æ£€æµ‹æŠ¥å‘Š': 3,
                'è®¤è¯è¯ä¹¦': 4
            }
            
            for tab_name, tab_index in tabs.items():
                try:
                    self.log(f"ğŸ”„ åˆ‡æ¢åˆ° {tab_name} æ ‡ç­¾é¡µ")
                    
                    # æ ¹æ®å®é™…HTMLç»“æ„æ›´æ–°é€‰æ‹©å™¨
                    # åŸºäºæä¾›çš„HTML: <ul data-v-a43cbdac="" class="tab-titles"><li data-v-a43cbdac="" class="active">å•†å“ä»‹ç»</li>
                    # å°è¯•å¤šç§XPathé€‰æ‹©å™¨æ¥æ‰¾åˆ°æ ‡ç­¾é¡µ
                    xpaths = [
                        f"//ul[contains(@class, 'tab-titles')]//li[contains(text(), '{tab_name}')]",
                        f"//li[contains(text(), '{tab_name}')]",
                        f"//div[contains(@class, 'tab')]//li[contains(text(), '{tab_name}')]",
                        f"//ul//li[contains(text(), '{tab_name}')]",
                        f"//div[contains(@class, 'el-tabs')]//div[contains(text(), '{tab_name}')]",
                        f"//ul[contains(@class, 'tab-titles')]//li[position()={tab_index + 1}]",
                        f"//ul//li[position()={tab_index + 1}]"
                    ]
                    
                    tab_element = None
                    for i, xpath in enumerate(xpaths):
                        try:
                            tab_element = WebDriverWait(self.driver, 2).until(
                                EC.element_to_be_clickable((By.XPATH, xpath))
                            )
                            self.log(f"   âœ… ä½¿ç”¨XPath{i+1}æ‰¾åˆ°æ ‡ç­¾é¡µ: {tab_name}")
                            break
                        except TimeoutException:
                            continue
                    
                    if tab_element:
                        try:
                            # æ»šåŠ¨åˆ°å…ƒç´ å¯è§
                            self.driver.execute_script("arguments[0].scrollIntoView();", tab_element)
                            time.sleep(1)
                            # ç‚¹å‡»æ ‡ç­¾é¡µ
                            tab_element.click()
                            time.sleep(3)
                            self.log(f"   âœ… æˆåŠŸåˆ‡æ¢åˆ° {tab_name} æ ‡ç­¾é¡µ")
                            # ä¿å­˜å½“å‰æ ‡ç­¾é¡µæˆªå›¾
                            self.save_tab_screenshot(category_name, subcategory_name, product_name, tab_name)
                        except Exception as click_e:
                            # å¦‚æœç‚¹å‡»å¤±è´¥ï¼Œå°è¯•JavaScriptç‚¹å‡»
                            try:
                                self.driver.execute_script("arguments[0].click();", tab_element)
                                time.sleep(3)
                                self.log(f"   âœ… ä½¿ç”¨JavaScriptæˆåŠŸåˆ‡æ¢åˆ° {tab_name} æ ‡ç­¾é¡µ")
                                # ä¿å­˜å½“å‰æ ‡ç­¾é¡µæˆªå›¾
                                self.save_tab_screenshot(category_name, subcategory_name, product_name, tab_name)
                            except Exception as js_e:
                                self.log(f"   âŒ ç‚¹å‡» {tab_name} æ ‡ç­¾é¡µå¤±è´¥: {str(js_e)}")
                                continue
                    else:
                        self.log(f"âš ï¸ æ— æ³•æ‰¾åˆ° {tab_name} æ ‡ç­¾é¡µï¼Œè·³è¿‡")
                        continue
                    
                    # è·å–å½“å‰æ ‡ç­¾é¡µçš„å†…å®¹
                    page_source = self.driver.page_source
                    soup = BeautifulSoup(page_source, 'html.parser')
                    
                    # æŸ¥æ‰¾ä¸‹è½½é“¾æ¥
                    tab_downloads = self.find_downloads_in_tab(soup, tab_name, category_name, subcategory_name, product_name)
                    downloads.extend(tab_downloads)
                    
                except Exception as e:
                    self.log(f"âŒ å¤„ç† {tab_name} æ ‡ç­¾é¡µæ—¶å‡ºé”™: {str(e)}")
                    continue
            
        except Exception as e:
            self.log(f"âŒ åˆ‡æ¢æ ‡ç­¾é¡µæ—¶å‡ºé”™: {str(e)}")
        
        return downloads

    def find_downloads_in_tab(self, soup, tab_name, category_name=None, subcategory_name=None, product_name=None):
        """åœ¨æ ‡ç­¾é¡µä¸­æŸ¥æ‰¾ä¸‹è½½å†…å®¹"""
        downloads = []
        
        try:
            # é¦–å…ˆæŸ¥æ‰¾å½“å‰æ¿€æ´»çš„æ ‡ç­¾é¡µå†…å®¹
            active_content = soup.find('div', class_=lambda x: x and 'content' in str(x) and 'active' in str(x))
            if not active_content:
                # å¦‚æœæ²¡æ‰¾åˆ°activeçš„ï¼Œå°±æŸ¥æ‰¾æ‰€æœ‰content divï¼Œå–æœ€åä¸€ä¸ª
                content_divs = soup.find_all('div', class_=lambda x: x and 'content' in str(x))
                if content_divs:
                    active_content = content_divs[-1]
            
            if not active_content:
                self.log(f"   âš ï¸ æœªæ‰¾åˆ°{tab_name}çš„å†…å®¹åŒºåŸŸ")
                return downloads
            
            if tab_name == 'å•†å“å‚æ•°':
                # å•†å“å‚æ•°ï¼šåªæŸ¥æ‰¾imgæ ‡ç­¾ï¼Œå› ä¸ºå‚æ•°æ˜¯ä»¥å›¾ç‰‡å½¢å¼å±•ç¤ºçš„
                images = active_content.find_all('img', src=True)
                for i, img in enumerate(images):
                    src = img.get('src', '')
                    if src and 'dmc.tengen.com.cn' in src:
                        # ç¡®ä¿URLå®Œæ•´
                        full_url = src if src.startswith('http') else f"https:{src}" if src.startswith('//') else urljoin(self.base_url, src)
                        
                        # æ ¹æ®URLç¡®å®šå›¾ç‰‡æ‰©å±•å
                        parsed_url = urlparse(full_url)
                        path = parsed_url.path.lower()
                        if '.jpg' in path or '.jpeg' in path:
                            extension = '.jpg'
                        elif '.png' in path:
                            extension = '.png'
                        elif '.webp' in path:
                            extension = '.webp'
                        elif '.gif' in path:
                            extension = '.gif'
                        else:
                            # ä»å“åº”å¤´è·å–MIMEç±»å‹ï¼ˆåå¤‡æ–¹æ¡ˆï¼‰
                            extension = '.png'  # é»˜è®¤æ‰©å±•å
                        
                        # ç”Ÿæˆå›¾ç‰‡æ–‡ä»¶å
                        image_filename = f'{tab_name}_å‚æ•°å›¾_{i+1}{extension}'
                        
                        downloads.append({
                            'title': f'{tab_name}_å‚æ•°å›¾_{i+1}',
                            'url': full_url,
                            'type': 'image',
                            'category': tab_name,
                            'filename': image_filename
                        })
                        self.log(f"   ğŸ–¼ï¸ æ‰¾åˆ°å‚æ•°å›¾ç‰‡: {os.path.basename(full_url)}")
                        
                        # ç«‹å³ä¸‹è½½å›¾ç‰‡ - ä½¿ç”¨æ™ºèƒ½ç›®å½•ç»“æ„
                        if category_name and subcategory_name and product_name:
                            # ä½¿ç”¨æ™ºèƒ½æ–‡ä»¶å¤¹è·¯å¾„æ„å»º
                            folder_path = self.get_smart_folder_path(category_name, subcategory_name, product_name, tab_name)
                        else:
                            folder_path = os.path.join(self.download_folder, self.safe_filename(tab_name))
                        
                        if self.download_file(full_url, image_filename, folder_path):
                            self.log(f"   âœ… ç«‹å³ä¸‹è½½å›¾ç‰‡æˆåŠŸ: {image_filename}")
                        else:
                            self.log(f"   âŒ ç«‹å³ä¸‹è½½å›¾ç‰‡å¤±è´¥: {image_filename}")
                        
                        # ä¸‹è½½é—´éš”ï¼Œç¡®ä¿é¡ºåºä¸‹è½½
                        time.sleep(1)
                
            else:
                # äº§å“æ ·æœ¬ã€æ£€æµ‹æŠ¥å‘Šã€è®¤è¯è¯ä¹¦ï¼šæŸ¥æ‰¾ä¸‹è½½è¡¨æ ¼å¹¶å°è¯•ç‚¹å‡»ä¸‹è½½æŒ‰é’®
                tables = active_content.find_all('table')
                for table in tables:
                    rows = table.find_all('tr')
                    for row in rows[1:]:  # è·³è¿‡è¡¨å¤´
                        cells = row.find_all(['td', 'th'])
                        if len(cells) >= 5:  # ç¡®ä¿æœ‰è¶³å¤Ÿçš„åˆ—ï¼ˆæ–‡ä»¶åã€ç±»å‹ã€å¤§å°ã€æŸ¥çœ‹ã€ä¸‹è½½ï¼‰
                            filename_cell = cells[0]
                            download_cell = cells[4]  # ä¸‹è½½åˆ—
                            
                            filename = filename_cell.get_text().strip()
                            
                            if filename:
                                # åœ¨å®é™…é¡µé¢ä¸­æ‰¾åˆ°å¯¹åº”çš„ä¸‹è½½æŒ‰é’®å¹¶ç‚¹å‡»
                                try:
                                    # å°è¯•å¤šç§xpathé€‰æ‹©å™¨æ¥é€‚é…ä¸åŒçš„æŒ‰é’®ç»“æ„
                                    download_button = None
                                    xpaths = [
                                        # ğŸ¯ æœ€ç²¾ç¡®åŒ¹é…ï¼šåœ¨è¡¨æ ¼ä¸­æ‰¾åˆ°åŒ…å«å®Œæ•´æ–‡ä»¶åçš„spanï¼Œç„¶åå®šä½åˆ°åŒè¡Œçš„ä¸‹è½½æŒ‰é’®
                                        f"//table//tr[td[@class='width250']//span[text()='{filename}']]//td[5]//button[contains(text(), 'ä¸‹è½½æ–‡ä»¶')]",
                                        # ğŸ¯ å¤‡é€‰ç²¾ç¡®åŒ¹é…ï¼šä½¿ç”¨containsåŒ¹é…æ–‡ä»¶å
                                        f"//table//tr[td[@class='width250']//span[contains(text(), '{filename}')]]//td[5]//button[contains(text(), 'ä¸‹è½½æ–‡ä»¶')]",
                                        # ğŸ¯ åŸºäºåˆ—ä½ç½®çš„åŒ¹é…ï¼šç¬¬5åˆ—ï¼ˆä¸‹è½½åˆ—ï¼‰
                                        f"//table//tr[.//span[contains(text(), '{filename}')]]//td[@class='width150'][last()]//button[contains(text(), 'ä¸‹è½½æ–‡ä»¶')]",
                                        # ğŸ¯ div.btnç»“æ„åŒ¹é…
                                        f"//table//tr[.//span[contains(text(), '{filename}')]]//div[@class='btn']//button[contains(text(), 'ä¸‹è½½æ–‡ä»¶')]",
                                        # ğŸ”„ é€šç”¨åŒ¹é…ï¼šä»»ä½•åŒ…å«æ–‡ä»¶åçš„è¡Œä¸­çš„ä¸‹è½½æŒ‰é’®
                                        f"//tr[.//span[contains(text(), '{filename}')]]//button[contains(text(), 'ä¸‹è½½æ–‡ä»¶')]",
                                        # ğŸ”„ å…¼å®¹æ—§ç‰ˆï¼šç›´æ¥åœ¨tdä¸­æŸ¥æ‰¾æ–‡ä»¶å
                                        f"//td[contains(text(), '{filename}')]/following-sibling::td//button[contains(text(), 'ä¸‹è½½æ–‡ä»¶')]",
                                        # ğŸ”„ æœ€å®½æ³›åŒ¹é…ï¼šè¯¥è¡Œä¸­ä»»ä½•ä¸‹è½½æŒ‰é’®
                                        f"//tr[.//span[contains(text(), '{filename}')]]//button[contains(text(), 'ä¸‹è½½')]"
                                    ]
                                    
                                    for i, xpath in enumerate(xpaths, 1):
                                        try:
                                            self.log(f"   ğŸ” å°è¯•XPath {i}/{len(xpaths)}: {xpath[:80]}...")
                                            download_button = self.driver.find_element(By.XPATH, xpath)
                                            if download_button and download_button.is_displayed() and download_button.is_enabled():
                                                self.log(f"   âœ… æˆåŠŸæ‰¾åˆ°ä¸‹è½½æŒ‰é’® (XPath {i}): {filename}")
                                                break
                                            else:
                                                self.log(f"   âš ï¸ æŒ‰é’®å­˜åœ¨ä½†ä¸å¯ç”¨ (XPath {i}): displayed={download_button.is_displayed()}, enabled={download_button.is_enabled()}")
                                        except Exception as e:
                                            self.log(f"   âŒ XPath {i} å¤±è´¥: {str(e)[:50]}...")
                                            continue
                                    
                                    if download_button:
                                        self.log(f"   ğŸ¯ å°è¯•ç‚¹å‡»ä¸‹è½½æŒ‰é’®: {filename}")
                                        
                                        # è®°å½•ä¸‹è½½å‰çš„çª—å£æ•°é‡
                                        initial_windows = len(self.driver.window_handles)
                                        
                                        # æ»šåŠ¨åˆ°æŒ‰é’®å¯è§å¹¶ç‚¹å‡»
                                        self.driver.execute_script("arguments[0].scrollIntoView();", download_button)
                                        time.sleep(1)
                                    else:
                                        self.log(f"   âŒ æ‰€æœ‰XPathéƒ½å¤±è´¥ï¼Œæ— æ³•æ‰¾åˆ°ä¸‹è½½æŒ‰é’®: {filename}")
                                        # è°ƒè¯•ï¼šè®°å½•é¡µé¢ä¸Šå®é™…å­˜åœ¨çš„ä¸‹è½½æŒ‰é’®
                                        try:
                                            all_download_buttons = self.driver.find_elements(By.XPATH, "//button[contains(text(), 'ä¸‹è½½')]")
                                            self.log(f"   ğŸ” é¡µé¢ä¸Šå…±æ‰¾åˆ° {len(all_download_buttons)} ä¸ªåŒ…å«'ä¸‹è½½'çš„æŒ‰é’®")
                                            for idx, btn in enumerate(all_download_buttons[:3]):  # åªæ˜¾ç¤ºå‰3ä¸ª
                                                try:
                                                    btn_text = btn.text.strip()
                                                    btn_visible = btn.is_displayed()
                                                    self.log(f"     æŒ‰é’®{idx+1}: '{btn_text}' (å¯è§: {btn_visible})")
                                                except:
                                                    pass
                                        except Exception as debug_e:
                                            self.log(f"   è°ƒè¯•ä¿¡æ¯è·å–å¤±è´¥: {debug_e}")
                                        continue
                                    
                                    # å¦‚æœæ‰¾åˆ°ä¸‹è½½æŒ‰é’®ï¼Œæ‰§è¡Œç‚¹å‡»æ“ä½œ
                                    if download_button:
                                        try:
                                            download_button.click()
                                        except Exception:
                                            # å¦‚æœæ™®é€šç‚¹å‡»å¤±è´¥ï¼Œå°è¯•JavaScriptç‚¹å‡»
                                            self.driver.execute_script("arguments[0].click();", download_button)
                                        
                                        time.sleep(2)  # ç­‰å¾…ä¸‹è½½å¼€å§‹
                                        
                                        # ç›‘æ§ç½‘ç»œè¯·æ±‚ï¼Œæ•è·å¯èƒ½çš„ä¸‹è½½é“¾æ¥
                                        captured_urls = self.monitor_network_requests()
                                        
                                        # æ£€æŸ¥æ˜¯å¦æœ‰æ–°çª—å£æ‰“å¼€ï¼ˆæŸäº›ä¸‹è½½å¯èƒ½åœ¨æ–°çª—å£ï¼‰
                                        current_windows = len(self.driver.window_handles)
                                        if current_windows > initial_windows:
                                            # å¦‚æœæœ‰æ–°çª—å£ï¼Œå…³é—­å®ƒ
                                            new_window = self.driver.window_handles[-1]
                                            self.driver.switch_to.window(new_window)
                                            new_url = self.driver.current_url
                                            self.driver.close()
                                            self.driver.switch_to.window(self.driver.window_handles[0])
                                            
                                            # å¦‚æœæ–°çª—å£åŒ…å«ä¸‹è½½é“¾æ¥ï¼Œè®°å½•ä¸‹æ¥
                                            # æ£€æµ‹å„ç§å¯èƒ½çš„ä¸‹è½½åŸŸåå’ŒURLæ ¼å¼
                                            is_download_url = any([
                                                'dmc.tengen.com.cn' in new_url,
                                                'tengen.com' in new_url and ('download' in new_url.lower() or 'file' in new_url.lower()),
                                                new_url.endswith('.pdf'),
                                                new_url.endswith('.doc'),
                                                new_url.endswith('.docx'),
                                                new_url.endswith('.xls'),
                                                new_url.endswith('.xlsx'),
                                                new_url.endswith('.zip'),
                                                new_url.endswith('.rar'),
                                                'getFile' in new_url,
                                                'blob:' in new_url,  # å¤„ç†blob URL
                                                new_url != 'about:blank' and new_url != self.driver.current_url
                                            ])
                                            
                                            if is_download_url:
                                                file_type = 'pdf'
                                                if len(cells) > 1:
                                                    type_text = cells[1].get_text().strip().lower()
                                                    if type_text in ['pdf', 'doc', 'docx', 'xls', 'xlsx', 'zip', 'rar']:
                                                        file_type = type_text
                                                
                                                downloads.append({
                                                    'title': f'{tab_name}_{filename}',
                                                    'url': new_url,
                                                    'type': file_type,
                                                    'category': tab_name,
                                                    'filename': filename
                                                })
                                                self.log(f"   âœ… è·å–åˆ°ä¸‹è½½é“¾æ¥: {filename} -> {new_url}")
                                                
                                                # ç«‹å³ä¸‹è½½æ–‡ä»¶ - ä½¿ç”¨æ™ºèƒ½ç›®å½•ç»“æ„
                                                if category_name and subcategory_name and product_name:
                                                    # ä½¿ç”¨æ™ºèƒ½æ–‡ä»¶å¤¹è·¯å¾„æ„å»ºï¼Œç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„å®¹å™¨ç±»å‹
                                                    folder_path = self.get_smart_folder_path(category_name, subcategory_name, product_name, tab_name)
                                                else:
                                                    folder_path = os.path.join(self.download_folder, self.safe_filename(tab_name))
                                                if self.download_file(new_url, filename, folder_path):
                                                    self.log(f"   âœ… ç«‹å³ä¸‹è½½æˆåŠŸ: {filename}")
                                                else:
                                                    self.log(f"   âŒ ç«‹å³ä¸‹è½½å¤±è´¥: {filename}")
                                                
                                                # ä¸‹è½½é—´éš”ï¼Œç¡®ä¿é¡ºåºä¸‹è½½
                                                time.sleep(2)
                                        else:
                                            # å¦‚æœæ²¡æœ‰æ–°çª—å£ï¼Œæ£€æŸ¥ç½‘ç»œç›‘æ§æ˜¯å¦æ•è·åˆ°ä¸‹è½½é“¾æ¥
                                            if captured_urls:
                                                # ä½¿ç”¨ç½‘ç»œç›‘æ§æ•è·çš„URL
                                                for captured_url in captured_urls:
                                                    file_type = 'pdf'
                                                    if len(cells) > 1:
                                                        type_text = cells[1].get_text().strip().lower()
                                                        if type_text in ['pdf', 'doc', 'docx', 'xls', 'xlsx', 'zip', 'rar']:
                                                            file_type = type_text
                                                    
                                                    downloads.append({
                                                        'title': f'{tab_name}_{filename}',
                                                        'url': captured_url,
                                                        'type': file_type,
                                                        'category': tab_name,
                                                        'filename': filename
                                                    })
                                                    self.log(f"   âœ… ç½‘ç»œç›‘æ§è·å–åˆ°ä¸‹è½½é“¾æ¥: {filename} -> {captured_url}")
                                                    
                                                    # ç«‹å³ä¸‹è½½æ–‡ä»¶ - ä½¿ç”¨æ™ºèƒ½ç›®å½•ç»“æ„
                                                    if category_name and subcategory_name and product_name:
                                                        # ä½¿ç”¨æ™ºèƒ½æ–‡ä»¶å¤¹è·¯å¾„æ„å»ºï¼Œç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„å®¹å™¨ç±»å‹
                                                        folder_path = self.get_smart_folder_path(category_name, subcategory_name, product_name, tab_name)
                                                    else:
                                                        folder_path = os.path.join(self.download_folder, self.safe_filename(tab_name))
                                                    if self.download_file(captured_url, filename, folder_path):
                                                        self.log(f"   âœ… ç«‹å³ä¸‹è½½æˆåŠŸ: {filename}")
                                                    else:
                                                        self.log(f"   âŒ ç«‹å³ä¸‹è½½å¤±è´¥: {filename}")
                                                    
                                                    # ä¸‹è½½é—´éš”ï¼Œç¡®ä¿é¡ºåºä¸‹è½½
                                                    time.sleep(2)
                                                    break  # åªå–ç¬¬ä¸€ä¸ªåŒ¹é…çš„URL
                                            else:
                                                # å¦‚æœç½‘ç»œç›‘æ§ä¹Ÿæ²¡æœ‰æ•è·åˆ°ï¼Œå°è¯•æ£€æŸ¥Chromeçš„ä¸‹è½½æ–‡ä»¶å¤¹
                                                self.log(f"   ğŸ”„ å°è¯•æ£€æŸ¥ç›´æ¥ä¸‹è½½: {filename}")
                                                
                                                # ç­‰å¾…ä¸€ä¼šå„¿è®©ä¸‹è½½å®Œæˆ
                                                time.sleep(3)
                                                
                                                # æ£€æŸ¥Chromeé»˜è®¤ä¸‹è½½ç›®å½•
                                                download_dir = os.path.expanduser("~/Downloads")
                                                potential_file = None
                                                
                                                # æŸ¥æ‰¾æœ€è¿‘ä¸‹è½½çš„æ–‡ä»¶
                                                try:
                                                    files_with_times = []
                                                    for file in os.listdir(download_dir):
                                                        file_path = os.path.join(download_dir, file)
                                                        if os.path.isfile(file_path):
                                                            ctime = os.path.getctime(file_path)
                                                            if ctime > time.time() - 60:  # 1åˆ†é’Ÿå†…åˆ›å»ºçš„æ–‡ä»¶
                                                                files_with_times.append((file_path, ctime))
                                                    
                                                    # æŒ‰åˆ›å»ºæ—¶é—´æ’åºï¼Œæœ€æ–°çš„åœ¨å‰
                                                    files_with_times.sort(key=lambda x: x[1], reverse=True)
                                                    
                                                    # æŸ¥æ‰¾åŒ¹é…çš„PDFæ–‡ä»¶
                                                    for file_path, ctime in files_with_times:
                                                        file = os.path.basename(file_path)
                                                        if file.lower().endswith('.pdf') and ('TGW1N' in file.upper() or 'pdf' in file.lower()):
                                                            self.log(f"   ğŸ” æ£€æŸ¥æ–‡ä»¶: {file} (åˆ›å»ºæ—¶é—´: {ctime})")
                                                            potential_file = file_path
                                                            break
                                                except Exception as e:
                                                    self.log(f"   âš ï¸ æ£€æŸ¥ä¸‹è½½ç›®å½•å‡ºé”™: {e}")
                                                
                                                if potential_file:
                                                    self.log(f"   âœ… æ£€æµ‹åˆ°ç›´æ¥ä¸‹è½½æ–‡ä»¶: {potential_file}")
                                                    
                                                    # ç¡®å®šæ–‡ä»¶ç±»å‹
                                                    file_type = 'pdf'
                                                    if len(cells) > 1:
                                                        type_text = cells[1].get_text().strip().lower()
                                                        if type_text in ['pdf', 'doc', 'docx', 'xls', 'xlsx', 'zip', 'rar']:
                                                            file_type = type_text
                                                    
                                                    downloads.append({
                                                        'title': f'{tab_name}_{filename}',
                                                        'url': f'file://{potential_file}',  # ä½¿ç”¨æœ¬åœ°æ–‡ä»¶è·¯å¾„
                                                        'type': file_type,
                                                        'category': tab_name,
                                                        'filename': filename,
                                                        'is_local_file': True
                                                    })
                                                else:
                                                    self.log(f"   âš ï¸ æœªæ£€æµ‹åˆ°ä¸‹è½½æ–‡ä»¶ï¼Œå¯èƒ½ä¸‹è½½å¤±è´¥: {filename}")
                                    else:
                                        self.log(f"   âŒ æœªæ‰¾åˆ°å¯ç”¨çš„ä¸‹è½½æŒ‰é’®: {filename}")
                                
                                except Exception as e:
                                    self.log(f"   âŒ ç‚¹å‡»ä¸‹è½½æŒ‰é’®å¤±è´¥: {filename} - {str(e)}")
                                    continue
            
            self.log(f"ğŸ“ åœ¨ {tab_name} ä¸­æ‰¾åˆ° {len(downloads)} ä¸ªä¸‹è½½é¡¹")
            
        except Exception as e:
            self.log(f"âŒ åœ¨ {tab_name} ä¸­æŸ¥æ‰¾ä¸‹è½½æ—¶å‡ºé”™: {str(e)}")
        
        return downloads

    def download_file(self, url, filename, folder_path):
        """ä¸‹è½½æ–‡ä»¶ - ç®€åŒ–ç‰ˆæœ¬ï¼Œå‚è€ƒè¯ºå¾·çˆ¬è™«"""
        try:
            # å¦‚æœæ²¡æœ‰URLï¼ˆè¯´æ˜æ˜¯é€šè¿‡æŒ‰é’®ç‚¹å‡»ç›´æ¥ä¸‹è½½ï¼‰ï¼Œè·³è¿‡
            if url is None:
                self.log(f"â­ï¸ è·³è¿‡æ— URLæ–‡ä»¶: {filename}")
                return True
                
            self.log(f"ğŸ”„ å¼€å§‹ä¸‹è½½: {filename}")
            self.log(f"   ğŸ“ ä¸‹è½½URL: {url}")
            
            # åˆ›å»ºç›®å½•
            os.makedirs(folder_path, exist_ok=True)
            file_path = os.path.join(folder_path, filename)
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
            if os.path.exists(file_path):
                file_size = os.path.getsize(file_path)
                if file_size > 1024:  # å¦‚æœæ–‡ä»¶å¤§äº1KBï¼Œè®¤ä¸ºæ˜¯æœ‰æ•ˆæ–‡ä»¶
                    self.log(f"ğŸ“ æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡: {filename}")
                    return True
                else:
                    self.log(f"ğŸ”„ æ–‡ä»¶å­˜åœ¨ä½†å¤§å°å¼‚å¸¸({file_size}å­—èŠ‚)ï¼Œé‡æ–°ä¸‹è½½: {filename}")
                    os.remove(file_path)
            
            # ä¸‹è½½æ–‡ä»¶ - ä½¿ç”¨æ›´å®Œæ•´çš„headers
            headers = {
                'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Referer': 'https://zx.tengen.com.cn/',
                'Accept': 'application/octet-stream, application/pdf, image/*, */*',
                'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
                'Accept-Encoding': 'gzip, deflate, br',
                'Connection': 'keep-alive'
            }
            
            # ä½¿ç”¨ç®€åŒ–çš„ä¸‹è½½é€»è¾‘ï¼Œå‚è€ƒè¯ºå¾·çˆ¬è™«
            response = requests.get(url, headers=headers, stream=True, timeout=60, allow_redirects=True)
            response.raise_for_status()
            
            # ç›´æ¥å†™å…¥ç›®æ ‡æ–‡ä»¶
            with open(file_path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:
                        f.write(chunk)
            
            # ç®€åŒ–çš„éªŒè¯
            file_size = os.path.getsize(file_path)
            
            # åŸºæœ¬å¤§å°æ£€æŸ¥ï¼šåªæ£€æŸ¥æ˜¯å¦ä¸ºç©ºæ–‡ä»¶
            if file_size == 0:
                self.log(f"âŒ æ–‡ä»¶ä¸ºç©ºï¼Œä¸‹è½½å¤±è´¥: {filename}")
                if os.path.exists(file_path):
                    os.remove(file_path)
                return False
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºé”™è¯¯é¡µé¢ï¼ˆç®€åŒ–ç‰ˆï¼‰
            if filename.endswith('.pdf') and file_size < 1000:
                try:
                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                        content = f.read(500)
                        if any(error in content.lower() for error in ['error', '404', '403', '500', 'not found', 'access denied']):
                            self.log(f"âŒ ä¸‹è½½çš„æ˜¯é”™è¯¯é¡µé¢ï¼Œåˆ é™¤: {filename}")
                            os.remove(file_path)
                            return False
                except:
                    pass  # å¦‚æœä¸èƒ½è¯»å–ä¸ºæ–‡æœ¬ï¼Œè¯´æ˜å¯èƒ½æ˜¯æœ‰æ•ˆçš„äºŒè¿›åˆ¶æ–‡ä»¶
            
            self.log(f"âœ… æ–‡ä»¶éªŒè¯é€šè¿‡: {filename}")
            self.log(f"âœ… ä¸‹è½½æˆåŠŸ: {filename} ({file_size} bytes)")
            
            self.new_files.append({
                'filename': filename,
                'path': file_path,
                'url': url,
                'size': file_size
            })
            return True
            
        except Exception as e:
            self.log(f"âŒ ä¸‹è½½å¤±è´¥ {filename}: {str(e)}")
            # æ¸…ç†å¯èƒ½çš„æ®‹ç•™æ–‡ä»¶
            if 'file_path' in locals() and os.path.exists(file_path):
                try:
                    os.remove(file_path)
                    self.log(f"   ğŸ§¹ å·²æ¸…ç†æ®‹ç•™æ–‡ä»¶: {filename}")
                except:
                    pass
            return False

    def move_local_file(self, source_path, filename, folder_path):
        """ç§»åŠ¨æœ¬åœ°æ–‡ä»¶åˆ°ç›®æ ‡æ–‡ä»¶å¤¹"""
        try:
            # åˆ›å»ºç›®å½•
            os.makedirs(folder_path, exist_ok=True)
            target_path = os.path.join(folder_path, filename)
            
            # æ£€æŸ¥æºæ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(source_path):
                self.log(f"âŒ æºæ–‡ä»¶ä¸å­˜åœ¨: {source_path}")
                return False
            
            # æ£€æŸ¥ç›®æ ‡æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
            if os.path.exists(target_path):
                target_size = os.path.getsize(target_path)
                if target_size > 1024:  # å¦‚æœæ–‡ä»¶å¤§äº1KBï¼Œè®¤ä¸ºæ˜¯æœ‰æ•ˆæ–‡ä»¶
                    self.log(f"ğŸ“ æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡: {filename}")
                    # åˆ é™¤æºæ–‡ä»¶ï¼ˆChromeä¸‹è½½çš„å‰¯æœ¬ï¼‰
                    try:
                        os.remove(source_path)
                    except:
                        pass
                    return True
                else:
                    # åˆ é™¤æ— æ•ˆçš„ç›®æ ‡æ–‡ä»¶
                    os.remove(target_path)
            
            # ç§»åŠ¨æ–‡ä»¶
            shutil.move(source_path, target_path)
            
            # éªŒè¯ç§»åŠ¨åçš„æ–‡ä»¶
            if os.path.exists(target_path):
                file_size = os.path.getsize(target_path)
                # å¯¹äºæœ¬åœ°æ–‡ä»¶ç§»åŠ¨ï¼ŒåªåšåŸºæœ¬éªŒè¯ï¼ˆæ–‡ä»¶å­˜åœ¨ä¸”å¤§å°å¤§äº0ï¼‰
                if file_size > 0:
                    self.log(f"âœ… æ–‡ä»¶ç§»åŠ¨æˆåŠŸ: {filename} ({file_size} bytes)")
                    return True
                else:
                    self.log(f"âŒ ç§»åŠ¨åæ–‡ä»¶ä¸ºç©º: {filename}")
                    os.remove(target_path)
                    return False
            else:
                self.log(f"âŒ æ–‡ä»¶ç§»åŠ¨å¤±è´¥: {filename}")
                return False
                
        except Exception as e:
            self.log(f"âŒ ç§»åŠ¨æ–‡ä»¶å¤±è´¥ {filename}: {str(e)}")
            return False

    def is_valid_file_size(self, filename, file_size):
        """æ£€æŸ¥æ–‡ä»¶å¤§å°æ˜¯å¦åˆç†"""
        try:
            # æ ¹æ®æ–‡ä»¶ç±»å‹å’Œåç§°åˆ¤æ–­æœ€å°å¤§å°
            filename_lower = filename.lower()
            
            # ä¸åŒç±»å‹æ–‡ä»¶çš„æœ€å°å¤§å°è¦æ±‚
            if any(keyword in filename_lower for keyword in ['å•†å“ä»‹ç»', 'äº§å“ä»‹ç»']):
                return file_size >= 5000  # è‡³å°‘5KB
            elif any(keyword in filename_lower for keyword in ['å•†å“å‚æ•°', 'äº§å“å‚æ•°', 'æŠ€æœ¯å‚æ•°']):
                return file_size >= 3000  # è‡³å°‘3KB
            elif any(keyword in filename_lower for keyword in ['äº§å“æ ·æœ¬', 'æ ·æœ¬', 'è¯´æ˜ä¹¦']):
                return file_size >= 100  # é™ä½è¦æ±‚åˆ°100å­—èŠ‚
            elif any(keyword in filename_lower for keyword in ['æ£€æµ‹æŠ¥å‘Š', 'æµ‹è¯•æŠ¥å‘Š']):
                return file_size >= 100  # é™ä½è¦æ±‚åˆ°100å­—èŠ‚
            elif any(keyword in filename_lower for keyword in ['è®¤è¯è¯ä¹¦', 'è¯ä¹¦']):
                return file_size >= 100  # é™ä½è¦æ±‚åˆ°100å­—èŠ‚
            else:
                # å…¶ä»–æ–‡ä»¶ç±»å‹
                file_ext = os.path.splitext(filename)[1].lower()
                if file_ext in ['.pdf']:
                    return file_size >= 100  # PDFè‡³å°‘100å­—èŠ‚ï¼ˆå¤§å¹…é™ä½è¦æ±‚ï¼‰
                elif file_ext in ['.jpg', '.jpeg', '.png', '.gif']:
                    return file_size >= 2000  # å›¾ç‰‡è‡³å°‘2KB
                elif file_ext in ['.doc', '.docx', '.xls', '.xlsx']:
                    return file_size >= 3000  # Officeæ–‡æ¡£è‡³å°‘3KB
                else:
                    return file_size >= 50   # å…¶ä»–æ–‡ä»¶è‡³å°‘50å­—èŠ‚
                    
        except Exception as e:
            self.log(f"âŒ æ£€æŸ¥æ–‡ä»¶å¤§å°æ—¶å‡ºé”™: {str(e)}")
            return True  # å‡ºé”™æ—¶é»˜è®¤å…è®¸ä¸‹è½½

    def validate_downloaded_file(self, file_path, filename, file_size):
        """éªŒè¯ä¸‹è½½çš„æ–‡ä»¶æ˜¯å¦æœ‰æ•ˆ"""
        try:
            # é¦–å…ˆæ£€æŸ¥æ–‡ä»¶å¤§å°
            if not self.is_valid_file_size(filename, file_size):
                self.log(f"âŒ æ–‡ä»¶å¤§å°ä¸åˆè§„: {filename} ({file_size} bytes)")
                return False
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦çœŸå®å­˜åœ¨
            if not os.path.exists(file_path):
                self.log(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                return False
            
            # æ£€æŸ¥å®é™…æ–‡ä»¶å¤§å°
            actual_size = os.path.getsize(file_path)
            if actual_size != file_size:
                self.log(f"âŒ æ–‡ä»¶å¤§å°ä¸åŒ¹é…: é¢„æœŸ{file_size}, å®é™…{actual_size}")
                return False
            
            # æ£€æŸ¥æ–‡ä»¶ç±»å‹å’Œå†…å®¹
            file_ext = os.path.splitext(filename)[1].lower()
            
            # PDFæ–‡ä»¶éªŒè¯
            if file_ext == '.pdf':
                with open(file_path, 'rb') as f:
                    header = f.read(10)
                    if not header.startswith(b'%PDF-'):
                        self.log(f"âŒ æ— æ•ˆçš„PDFæ–‡ä»¶: {filename}")
                        return False
            
            # å›¾ç‰‡æ–‡ä»¶éªŒè¯
            elif file_ext in ['.jpg', '.jpeg', '.png', '.gif']:
                with open(file_path, 'rb') as f:
                    header = f.read(10)
                    # æ£€æŸ¥å¸¸è§å›¾ç‰‡æ ¼å¼çš„æ–‡ä»¶å¤´
                    valid_headers = [
                        b'\xff\xd8\xff',  # JPEG
                        b'\x89PNG\r\n\x1a\n',  # PNG
                        b'GIF87a',  # GIF87a
                        b'GIF89a'   # GIF89a
                    ]
                    
                    is_valid_image = any(header.startswith(h) for h in valid_headers)
                    if not is_valid_image:
                        self.log(f"âŒ æ— æ•ˆçš„å›¾ç‰‡æ–‡ä»¶: {filename}")
                        return False
            
            # Wordæ–‡æ¡£éªŒè¯
            elif file_ext in ['.doc', '.docx']:
                with open(file_path, 'rb') as f:
                    header = f.read(8)
                    if file_ext == '.docx':
                        # DOCXæ–‡ä»¶å®é™…ä¸Šæ˜¯ZIPæ ¼å¼
                        if not header.startswith(b'PK'):
                            self.log(f"âŒ æ— æ•ˆçš„DOCXæ–‡ä»¶: {filename}")
                            return False
                    elif file_ext == '.doc':
                        # DOCæ–‡ä»¶çš„Magic Number
                        if not (header.startswith(b'\xd0\xcf\x11\xe0') or header.startswith(b'\xdb\xa5')):
                            self.log(f"âŒ æ— æ•ˆçš„DOCæ–‡ä»¶: {filename}")
                            return False
            
            # Excelæ–‡æ¡£éªŒè¯
            elif file_ext in ['.xls', '.xlsx']:
                with open(file_path, 'rb') as f:
                    header = f.read(8)
                    if file_ext == '.xlsx':
                        if not header.startswith(b'PK'):
                            self.log(f"âŒ æ— æ•ˆçš„XLSXæ–‡ä»¶: {filename}")
                            return False
                    elif file_ext == '.xls':
                        if not header.startswith(b'\xd0\xcf\x11\xe0'):
                            self.log(f"âŒ æ— æ•ˆçš„XLSæ–‡ä»¶: {filename}")
                            return False
            
            # HTMLæ–‡ä»¶æ£€æŸ¥ï¼ˆé˜²æ­¢ä¸‹è½½åˆ°é”™è¯¯é¡µé¢ï¼‰
            elif file_ext in ['.html', '.htm']:
                try:
                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                        content = f.read(1000)  # è¯»å–å‰1000ä¸ªå­—ç¬¦
                        # æ£€æŸ¥æ˜¯å¦åŒ…å«é”™è¯¯é¡µé¢çš„æ ‡è¯†
                        error_indicators = ['404', 'Not Found', 'é¡µé¢ä¸å­˜åœ¨', 'é”™è¯¯', 'Error', 'æ— æ³•æ‰¾åˆ°']
                        if any(indicator in content for indicator in error_indicators):
                            self.log(f"âŒ æ£€æµ‹åˆ°é”™è¯¯é¡µé¢: {filename}")
                            return False
                except:
                    # å¦‚æœæ— æ³•è¯»å–ä¸ºæ–‡æœ¬ï¼Œå¯èƒ½æ˜¯äºŒè¿›åˆ¶æ–‡ä»¶è¢«é”™è¯¯å‘½å
                    pass
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯åªæœ‰æ–‡ä»¶åæ²¡æœ‰å®é™…å†…å®¹çš„æ–‡ä»¶
            filename_only_indicators = [
                'ä»…æ–‡ä»¶å',
                'ç©ºæ–‡ä»¶',
                'placeholder',
                'empty'
            ]
            
            filename_lower = filename.lower()
            if any(indicator in filename_lower for indicator in filename_only_indicators):
                self.log(f"âŒ æ£€æµ‹åˆ°ä»…æ–‡ä»¶åçš„æ–‡ä»¶: {filename}")
                return False
            
            # é€šè¿‡æ‰€æœ‰éªŒè¯
            self.log(f"âœ… æ–‡ä»¶éªŒè¯é€šè¿‡: {filename}")
            return True
            
        except Exception as e:
            self.log(f"âŒ æ–‡ä»¶éªŒè¯å‡ºé”™: {str(e)}")
            return False  # éªŒè¯å‡ºé”™æ—¶é»˜è®¤æ‹’ç»

    def save_text_content(self, content, filename, folder_path):
        """ä¿å­˜æ–‡æœ¬å†…å®¹"""
        try:
            os.makedirs(folder_path, exist_ok=True)
            file_path = os.path.join(folder_path, filename)
            
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(content)
            
            file_size = os.path.getsize(file_path)
            self.log(f"âœ… ä¿å­˜æ–‡æœ¬: {filename} ({file_size} bytes)")
            
            self.new_files.append({
                'filename': filename,
                'path': file_path,
                'content': content[:100] + '...' if len(content) > 100 else content,
                'size': file_size
            })
            
            return True
            
        except Exception as e:
            self.log(f"âŒ ä¿å­˜æ–‡æœ¬å¤±è´¥ {filename}: {str(e)}")
            return False

    def safe_filename(self, filename):
        """ç”Ÿæˆå®‰å…¨çš„æ–‡ä»¶å"""
        import re
        # ç§»é™¤æˆ–æ›¿æ¢ä¸å®‰å…¨çš„å­—ç¬¦
        filename = re.sub(r'[<>:"/\\|?*]', '_', filename)
        # ç§»é™¤å¤šä½™çš„ç©ºæ ¼å’Œç‚¹å·
        filename = re.sub(r'\s+', ' ', filename).strip()
        filename = filename.strip('.')
        # ç¡®ä¿æ–‡ä»¶åä¸ä¸ºç©º
        if not filename:
            filename = 'untitled'
        return filename
    
    def clean_filename(self, filename):
        """æ¸…ç†æ–‡ä»¶åï¼Œç§»é™¤ä¸å®‰å…¨å­—ç¬¦"""
        import re
        # ç§»é™¤æˆ–æ›¿æ¢ä¸å®‰å…¨çš„å­—ç¬¦
        safe_name = re.sub(r'[<>:"/\\|?*\x00-\x1f]', '_', filename)
        # ç§»é™¤å¤šä½™çš„ç©ºæ ¼
        safe_name = re.sub(r'\s+', ' ', safe_name).strip()
        # ç§»é™¤å¼€å¤´å’Œç»“å°¾çš„ç‚¹å·
        safe_name = safe_name.strip('.')
        # ç¡®ä¿ä¸ä¸ºç©º
        if not safe_name:
            safe_name = 'untitled'
        return safe_name
    
    def generate_filename(self, url, title, category, file_type='file'):
        """ç”Ÿæˆæ–‡ä»¶å"""
        try:
            # æ¸…ç†æ ‡é¢˜
            safe_title = "".join(c for c in title if c.isalnum() or c in (' ', '-', '_', 'ï¼ˆ', 'ï¼‰', '(', ')')).strip()
            safe_title = re.sub(r'\s+', '_', safe_title)
            safe_title = safe_title[:50]  # é™åˆ¶é•¿åº¦
            
            if not safe_title:
                safe_title = f"document_{int(time.time())}"
            
            # ç¡®å®šæ–‡ä»¶æ‰©å±•å
            if file_type == 'text':
                extension = '.txt'
            elif file_type == 'image':
                # ä»URLç¡®å®šå›¾ç‰‡æ‰©å±•å
                parsed_url = urlparse(url)
                path = parsed_url.path.lower()
                if '.png' in path:
                    extension = '.png'
                elif '.jpg' in path or '.jpeg' in path:
                    extension = '.jpg'
                elif '.webp' in path:
                    extension = '.webp'
                else:
                    extension = '.png'  # é»˜è®¤
            else:
                # æ–‡ä»¶ç±»å‹ï¼Œä»URLç¡®å®šæ‰©å±•å
                parsed_url = urlparse(url)
                path = parsed_url.path.lower()
                if '.pdf' in path:
                    extension = '.pdf'
                elif '.doc' in path:
                    extension = '.doc'
                elif '.xlsx' in path:
                    extension = '.xlsx'
                else:
                    extension = '.pdf'  # é»˜è®¤
            
            filename = f"{safe_title}{extension}"
            return filename
            
        except Exception as e:
            self.log(f"âš ï¸ æ–‡ä»¶åç”Ÿæˆå¤±è´¥: {str(e)}")
            return f"document_{int(time.time())}.pdf"

    def process_product(self, product, category_name, subcategory_name):
        """å¤„ç†å•ä¸ªäº§å“"""
        product_name = product['name']
        product_url = product['url']
        box_type = product.get('box_type', '')  # è·å–äº§å“æ¥è‡ªå“ªä¸ªå®¹å™¨
        
        if product_url in self.processed_urls:
            self.log(f"â­ï¸ è·³è¿‡å·²å¤„ç†äº§å“: {product_name}")
            return
        
        self.log(f"ğŸ“„ å¤„ç†äº§å“: {product_name} (æ¥è‡ª{box_type}å®¹å™¨)")
        
        # è®¾ç½®å½“å‰äº§å“çš„å®¹å™¨ç±»å‹ï¼Œç”¨äºæ–‡ä»¶å¤¹è·¯å¾„ç”Ÿæˆ
        self.current_product_box_type = box_type
        
        # è·å–äº§å“è¯¦æƒ…é¡µURL
        detail_url = self.get_product_detail_url(product_url)
        if not detail_url:
            self.log(f"âŒ æ— æ³•è·å–äº§å“è¯¦æƒ…é¡µ: {product_name}ï¼Œè·³è¿‡æ­¤äº§å“")
            # æ ‡è®°ä¸ºå·²å¤„ç†ï¼Œé¿å…é‡å¤å°è¯•
            self.processed_urls.add(product_url)
            return
        
        # åˆ‡æ¢æ ‡ç­¾é¡µå¹¶è·å–ä¸‹è½½å†…å®¹
        downloads = self.switch_to_product_detail_tabs(detail_url, category_name, subcategory_name, product_name)
        
        if downloads:
            self.log(f"âœ… åœ¨äº§å“ {product_name} ä¸­æ‰¾åˆ° {len(downloads)} ä¸ªä¸‹è½½é¡¹")
            
            # å¤„ç†æ–‡æœ¬å†…å®¹ï¼ˆåªæœ‰æ–‡æœ¬å†…å®¹éœ€è¦åœ¨è¿™é‡Œä¿å­˜ï¼Œæ–‡ä»¶å·²ç»åœ¨ find_downloads_in_tab ä¸­ä¸‹è½½äº†ï¼‰
            for download in downloads:
                download_type = download.get('type', 'file')
                
                if download_type == 'text':
                    # ä½¿ç”¨æ™ºèƒ½æ–‡ä»¶å¤¹è·¯å¾„æ„å»º
                    category = download.get('category', 'å…¶ä»–')
                    category_folder = self.get_smart_folder_path(category_name, subcategory_name, product_name, category)
                    
                    # ä¿å­˜æ–‡æœ¬å†…å®¹
                    filename = self.generate_filename('', download['title'], category, 'text')
                    self.save_text_content(download['content'], filename, category_folder)
                    self.log(f"âœ… ä¿å­˜æ–‡æœ¬å†…å®¹: {filename}")
                    
                    time.sleep(0.5)  # çŸ­æš‚é—´éš”
        
        # æ ‡è®°ä¸ºå·²å¤„ç†
        self.processed_urls.add(product_url)
        
        # æ¸…ç†å½“å‰äº§å“å®¹å™¨ç±»å‹
        self.current_product_box_type = None

    def crawl_subcategory(self, subcategory, category_name):
        """çˆ¬å–å­åˆ†ç±» - åªå¤„ç†é«˜å‹äº¤æµçœŸç©ºæ–­æµå™¨"""
        subcategory_name = subcategory['name']
        subcategory_url = subcategory['url']
        
        # éªŒè¯æ˜¯å¦ä¸ºæŒ‡å®šçš„æ§åˆ¶ç”µå™¨å­åˆ†ç±»
        allowed_subcategories = ['é«˜å‹äº¤æµçœŸç©ºæ–­æµå™¨']
        if subcategory_name not in allowed_subcategories:
            self.log(f"â­ï¸ è·³è¿‡éæŒ‡å®šå­åˆ†ç±»: {subcategory_name}")
            return
        
        self.log(f"ğŸ” çˆ¬å–æ§åˆ¶ç”µå™¨å­åˆ†ç±»: {subcategory_name}")
        
        soup = self.visit_page(subcategory_url)
        if not soup:
            return
        
        # æŸ¥æ‰¾äº§å“åˆ—è¡¨
        products = self.find_products(soup, subcategory_name)
        
        if products:
            self.log(f"ğŸ“‹ åœ¨ {subcategory_name} ä¸­æ‰¾åˆ° {len(products)} ä¸ªäº§å“")
            
            # å¤„ç†æ‰€æœ‰æ‰¾åˆ°çš„äº§å“
            for i, product in enumerate(products):
                try:
                    self.log(f"ğŸ”„ å¤„ç†äº§å“ {i+1}/{len(products)}: {product['name']}")
                    self.process_product(product, category_name, subcategory_name)
                    time.sleep(2)  # äº§å“é—´å»¶è¿Ÿ
                except Exception as e:
                    self.log(f"âŒ å¤„ç†äº§å“ {product['name']} æ—¶å‡ºé”™: {str(e)}")
                    # ç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªäº§å“
                    continue
        else:
            self.log(f"â­ï¸ {subcategory_name} æš‚æ— äº§å“ï¼Œè·³è¿‡æ­¤åˆ†ç±»")
        
        self.log(f"âœ… å®Œæˆå­åˆ†ç±»: {subcategory_name}")

    def crawl_category(self, category):
        """çˆ¬å–ä¸»åˆ†ç±» - åªå¤„ç†æ§åˆ¶ç”µå™¨"""
        category_name = category['name']
        category_url = category['url']
        
        # éªŒè¯æ˜¯å¦ä¸ºæ§åˆ¶ç”µå™¨åˆ†ç±»
        if category_name != 'æ§åˆ¶ç”µå™¨':
            self.log(f"â­ï¸ è·³è¿‡éæ§åˆ¶ç”µå™¨åˆ†ç±»: {category_name}")
            return
        
        self.log(f"ğŸš€ å¼€å§‹çˆ¬å–æ§åˆ¶ç”µå™¨åˆ†ç±»: {category_name}")
        
        soup = self.visit_page(category_url)
        if not soup:
            return
        
        # æŸ¥æ‰¾å­åˆ†ç±»
        subcategories = self.find_subcategories(soup, category_name)
        
        if subcategories:
            self.log(f"ğŸ“‹ åœ¨ {category_name} ä¸­æ‰¾åˆ° {len(subcategories)} ä¸ªå­åˆ†ç±»")
            
            # å¤„ç†æ‰€æœ‰å­åˆ†ç±»ï¼ˆç»§ç”µå™¨å’Œæ¥è§¦å™¨ï¼‰
            for subcategory in subcategories:
                self.crawl_subcategory(subcategory, category_name)
                time.sleep(3)  # å­åˆ†ç±»é—´å»¶è¿Ÿ
        else:
            self.log(f"âš ï¸ {category_name} ä¸­æœªæ‰¾åˆ°å­åˆ†ç±»")
        
        self.log(f"âœ… å®Œæˆåˆ†ç±»: {category_name}")

    def run(self):
        """è¿è¡Œçˆ¬è™« - åªçˆ¬å–æ§åˆ¶ç”µå™¨çš„é«˜å‹äº¤æµçœŸç©ºæ–­æµå™¨"""
        try:
            self.log("ğŸš€ å¼€å§‹è¿è¡Œå¤©æ­£äº§å“çˆ¬è™« - é«˜å‹äº¤æµçœŸç©ºæ–­æµå™¨ä¸“ç”¨ç‰ˆæœ¬")
            self.log("=" * 60)
            self.log("ğŸ“‹ ç›®æ ‡æ¨¡å—:")
            self.log("   æ§åˆ¶ç”µå™¨:")
            self.log("     - é«˜å‹äº¤æµçœŸç©ºæ–­æµå™¨ (gaoyawuwaiduanluqi)")
            self.log("=" * 60)
            
            # çˆ¬å–æ§åˆ¶ç”µå™¨åˆ†ç±»
            for i, category in enumerate(self.main_categories, 1):
                self.log(f"\nğŸ”„ å¤„ç†åˆ†ç±» {i}/{len(self.main_categories)}: {category['name']}")
                self.crawl_category(category)
                if i < len(self.main_categories):  # æœ€åä¸€ä¸ªåˆ†ç±»ä¸éœ€è¦å»¶è¿Ÿ
                    time.sleep(5)  # ä¸»åˆ†ç±»é—´å»¶è¿Ÿ
            
            # ä¿å­˜è¿›åº¦
            self.save_processed_urls()
            
            # ç»Ÿè®¡ç»“æœ
            total_files = len(self.new_files)
            self.log(f"\nğŸ‰ çˆ¬å–å®Œæˆï¼å…±ä¸‹è½½ {total_files} ä¸ªæ–°æ–‡ä»¶")
            
            if self.new_files:
                self.log("ğŸ“ æ–°ä¸‹è½½çš„æ–‡ä»¶:")
                for file_info in self.new_files[:10]:  # æ˜¾ç¤ºå‰10ä¸ª
                    self.log(f"   ğŸ“„ {file_info['filename']} ({file_info['size']} bytes)")
                
                if len(self.new_files) > 10:
                    self.log(f"   ... è¿˜æœ‰ {len(self.new_files) - 10} ä¸ªæ–‡ä»¶")
            
        except Exception as e:
            self.log(f"âŒ çˆ¬è™«è¿è¡Œå‡ºé”™: {str(e)}")
            
        finally:
            # å‘é€é€šçŸ¥
            if self.new_files:
                self.send_notifications()
            
            # å…³é—­WebDriver
            if self.driver:
                self.driver.quit()
                self.log("ğŸ”’ WebDriverå·²å…³é—­")

    def send_dingtalk_notification(self, message):
        """å‘é€é’‰é’‰é€šçŸ¥"""
        try:
            timestamp = str(round(time.time() * 1000))
            string_to_sign = f'{timestamp}\n{self.SECRET}'
            hmac_code = hmac.new(self.SECRET.encode(), string_to_sign.encode(), hashlib.sha256).digest()
            sign = urllib.parse.quote_plus(base64.b64encode(hmac_code))

            url = f'https://oapi.dingtalk.com/robot/send?access_token={self.ACCESS_TOKEN}&timestamp={timestamp}&sign={sign}'
            headers = {'Content-Type': 'application/json'}
            data = {
                "msgtype": "text",
                "text": {"content": message},
                "at": {"isAtAll": False}
            }

            response = requests.post(url, json=data, headers=headers)
            self.log(f"ğŸ“¨ é’‰é’‰é€šçŸ¥å“åº”ï¼š{response.status_code} {response.text}")
            return response.status_code == 200
        except Exception as e:
            self.log(f"âŒ é’‰é’‰é€šçŸ¥å‘é€å¤±è´¥: {e}")
            return False

    def send_notifications(self):
        """å‘é€æ–°å¢æ–‡ä»¶é€šçŸ¥"""
        try:
            if not self.new_files:
                return
            
            # æ§åˆ¶å°é€šçŸ¥
            self.log(f"\nğŸ‰ çˆ¬å–å®Œæˆé€šçŸ¥:")
            self.log("=" * 60)
            self.log(f"ğŸ“Š å‘ç° {len(self.new_files)} ä¸ªæ–°æ–‡ä»¶:")
            
            # æŒ‰ç±»å‹ç»Ÿè®¡ - å»é™¤å•†å“ä»‹ç»
            type_counts = {}
            for file_info in self.new_files:
                # æ ¹æ®è·¯å¾„åˆ¤æ–­æ–‡ä»¶ç±»å‹
                path = file_info.get('path', '')
                if 'å•†å“å‚æ•°' in path:
                    file_type = 'å•†å“å‚æ•°'
                elif 'äº§å“æ ·æœ¬' in path:
                    file_type = 'äº§å“æ ·æœ¬'
                elif 'æ£€æµ‹æŠ¥å‘Š' in path:
                    file_type = 'æ£€æµ‹æŠ¥å‘Š'
                elif 'è®¤è¯è¯ä¹¦' in path:
                    file_type = 'è®¤è¯è¯ä¹¦'
                else:
                    file_type = 'å…¶ä»–æ–‡ä»¶'
                
                type_counts[file_type] = type_counts.get(file_type, 0) + 1
            
            for file_type, count in type_counts.items():
                self.log(f"  ğŸ“ {file_type}: {count} ä¸ª")
            
            self.log(f"\nğŸ“‚ æœ€æ–°æ–‡ä»¶é¢„è§ˆ:")
            for file_info in self.new_files[:5]:  # æ˜¾ç¤ºå‰5ä¸ª
                size_str = f" ({file_info['size']} bytes)" if 'size' in file_info else ""
                self.log(f"  ğŸ“„ {file_info['filename']}{size_str}")
            
            if len(self.new_files) > 5:
                self.log(f"  ... è¿˜æœ‰ {len(self.new_files) - 5} ä¸ªæ–‡ä»¶")
                
            self.log(f"\nğŸ’¾ æ‰€æœ‰æ–‡ä»¶å·²ä¿å­˜è‡³: {self.base_dir}")
            
            # é’‰é’‰é€šçŸ¥
            current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            total_files = len(self.new_files)
            success_rate = 100.0  # å‡è®¾å…¨éƒ¨æˆåŠŸ
            
            if self.is_first_run:
                # ç¬¬ä¸€æ¬¡å…¨é‡çˆ¬å–é€šçŸ¥
                message = f"""âœ… å¤©æ­£ çˆ¬å–æˆåŠŸï¼Œè¯·åŠæ—¶å®¡æ ¸

ğŸ“Š ä¸‹è½½ç»Ÿè®¡:
  æˆåŠŸä¸‹è½½: {total_files} ä¸ªæ–‡ä»¶
  æ€»æ–‡ä»¶æ•°: {total_files} ä¸ªæ–‡ä»¶
  æˆåŠŸç‡: {success_rate}%

ğŸ“ æ–‡ä»¶å­˜æ”¾è·¯å¾„: /srv/downloads/approved/
â° å®Œæˆæ—¶é—´: {current_time}"""
            else:
                # å¢é‡çˆ¬å–é€šçŸ¥
                message = f"""âœ… å¤©æ­£ å¢é‡çˆ¬å–æˆåŠŸï¼Œè¯·åŠæ—¶å®¡æ ¸

ğŸ“Š ä¸‹è½½ç»Ÿè®¡:
  æˆåŠŸä¸‹è½½: {total_files} ä¸ªæ–‡ä»¶
  æ€»æ–‡ä»¶æ•°: {total_files} ä¸ªæ–‡ä»¶
  æˆåŠŸç‡: {success_rate}%
æ–‡ä»¶æ˜ç»†ï¼š"""
                
                # æ·»åŠ æ–‡ä»¶æ˜ç»†
                for file_info in self.new_files:
                    # æ„å»ºç›¸å¯¹è·¯å¾„ï¼ˆä»å¤©æ­£å¼€å§‹ï¼‰
                    relative_path = file_info['path'].replace('/srv/downloads/approved/', '')
                    message += f"\n{relative_path}"
                
                message += f"""

ğŸ“ æ–‡ä»¶å­˜æ”¾è·¯å¾„: /srv/downloads/approved/
â° å®Œæˆæ—¶é—´: {current_time}"""
            
            # å‘é€é’‰é’‰é€šçŸ¥
            self.send_dingtalk_notification(message)
            
        except Exception as e:
            self.log(f"âŒ å‘é€é€šçŸ¥å¤±è´¥: {e}")

    def is_product_title(self, text, subcategory_name):
        """æ™ºèƒ½åˆ¤æ–­æ˜¯å¦ä¸ºäº§å“æ ‡é¢˜"""
        # è¿‡æ»¤æ‰æ˜æ˜¾çš„éäº§å“æ–‡æœ¬
        exclude_keywords = [
            'é¦–é¡µ', 'å…³äºæˆ‘ä»¬', 'è”ç³»æˆ‘ä»¬', 'æ–°é—»', 'å…¬å‘Š', 'ä¸‹è½½', 'æŠ€æœ¯æ”¯æŒ',
            'æœåŠ¡', 'è§£å†³æ–¹æ¡ˆ', 'åº”ç”¨æ¡ˆä¾‹', 'æŠ€æœ¯å‚æ•°', 'äº§å“ä»‹ç»', 'äº§å“å±•ç¤º',
            'å…¬å¸ç®€ä»‹', 'ä¼ä¸šæ–‡åŒ–', 'å‘å±•å†ç¨‹', 'è£èª‰èµ„è´¨', 'æ‹›è˜ä¿¡æ¯',
            'è¿”å›é¡¶éƒ¨', 'ç½‘ç«™åœ°å›¾', 'å‹æƒ…é“¾æ¥', 'ç‰ˆæƒå£°æ˜', 'åœ¨çº¿å®¢æœ'
        ]
        
        if any(keyword in text for keyword in exclude_keywords):
            return False
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«äº§å“ç‰¹å¾
        product_indicators = [
            # å‹å·ç‰¹å¾
            'TG', 'DW', 'RT', 'DZ', 'NB', 'NM', 'NS', 'NT', 'NX', 'NY',
            # äº§å“ç±»å‹
            'æ–­è·¯å™¨', 'å¼€å…³', 'ä¿æŠ¤å™¨', 'æ¥è§¦å™¨', 'ç»§ç”µå™¨', 'å˜å‹å™¨', 'äº’æ„Ÿå™¨',
            'æ§åˆ¶å™¨', 'ä»ªè¡¨', 'ç”µè¡¨', 'å˜é¢‘å™¨', 'è½¯å¯åŠ¨å™¨', 'ç”µå®¹å™¨',
            # æŠ€æœ¯ç‰¹å¾
            'ç³»åˆ—', 'å‹å·', 'è§„æ ¼', 'ç”µæµ', 'ç”µå‹', 'åŠŸç‡', 'é¢‘ç‡',
            # å“ç‰Œç‰¹å¾
            'å¤©æ­£', 'TENGEN', 'TENGEN ELECTRIC'
        ]
        
        # å¦‚æœåŒ…å«äº§å“ç‰¹å¾ï¼Œè®¤ä¸ºæ˜¯äº§å“æ ‡é¢˜
        if any(indicator in text for indicator in product_indicators):
            return True
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºå‹å·æ ¼å¼ï¼ˆå­—æ¯+æ•°å­—çš„ç»„åˆï¼‰
        if re.search(r'[A-Z]{2,}\d+', text):
            return True
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æŠ€æœ¯å‚æ•°
        if re.search(r'\d+[A-Z]?', text) and any(keyword in text for keyword in ['A', 'V', 'W', 'Hz', 'kW']):
            return True
        
        return False
    
    def is_product_title_relaxed(self, text, subcategory_name):
        """å®½æ¾çš„äº§å“æ ‡é¢˜åˆ¤æ–­ - ç”¨äºæœ€åçš„å¤‡ç”¨æ–¹æ³•"""
        # è¿‡æ»¤æ‰æ˜æ˜¾çš„éäº§å“æ–‡æœ¬
        exclude_keywords = [
            'é¦–é¡µ', 'å…³äºæˆ‘ä»¬', 'è”ç³»æˆ‘ä»¬', 'æ–°é—»', 'å…¬å‘Š', 'ä¸‹è½½', 'æŠ€æœ¯æ”¯æŒ',
            'æœåŠ¡', 'è§£å†³æ–¹æ¡ˆ', 'åº”ç”¨æ¡ˆä¾‹', 'æŠ€æœ¯å‚æ•°', 'äº§å“ä»‹ç»', 'äº§å“å±•ç¤º',
            'å…¬å¸ç®€ä»‹', 'ä¼ä¸šæ–‡åŒ–', 'å‘å±•å†ç¨‹', 'è£èª‰èµ„è´¨', 'æ‹›è˜ä¿¡æ¯',
            'è¿”å›é¡¶éƒ¨', 'ç½‘ç«™åœ°å›¾', 'å‹æƒ…é“¾æ¥', 'ç‰ˆæƒå£°æ˜', 'åœ¨çº¿å®¢æœ'
        ]
        
        if any(keyword in text for keyword in exclude_keywords):
            return False
        
        # æ›´å®½æ¾çš„äº§å“ç‰¹å¾æ£€æŸ¥
        product_indicators = [
            # åŸºç¡€äº§å“ç±»å‹
            'æ–­è·¯å™¨', 'å¼€å…³', 'ä¿æŠ¤å™¨', 'æ¥è§¦å™¨', 'ç»§ç”µå™¨', 'å˜å‹å™¨', 'äº’æ„Ÿå™¨',
            'æ§åˆ¶å™¨', 'ä»ªè¡¨', 'ç”µè¡¨', 'å˜é¢‘å™¨', 'è½¯å¯åŠ¨å™¨', 'ç”µå®¹å™¨',
            # æŠ€æœ¯ç‰¹å¾
            'ç³»åˆ—', 'å‹å·', 'è§„æ ¼', 'ç”µæµ', 'ç”µå‹', 'åŠŸç‡', 'é¢‘ç‡',
            # å“ç‰Œç‰¹å¾
            'å¤©æ­£', 'TENGEN'
        ]
        
        # å¦‚æœåŒ…å«äº§å“ç‰¹å¾ï¼Œè®¤ä¸ºæ˜¯äº§å“æ ‡é¢˜
        if any(indicator in text for indicator in product_indicators):
            return True
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºå‹å·æ ¼å¼ï¼ˆå­—æ¯+æ•°å­—çš„ç»„åˆï¼‰
        if re.search(r'[A-Z]{2,}\d+', text):
            return True
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æŠ€æœ¯å‚æ•°
        if re.search(r'\d+[A-Z]?', text) and any(keyword in text for keyword in ['A', 'V', 'W', 'Hz', 'kW']):
            return True
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«äº§å“ç›¸å…³è¯æ±‡
        product_related = ['äº§å“', 'ç³»åˆ—', 'å‹å·', 'è§„æ ¼', 'å‚æ•°', 'æŠ€æœ¯', 'ç”µæ°”', 'è®¾å¤‡']
        if any(keyword in text for keyword in product_related):
            return True
        
        return False
    
    def is_product_with_subcategories(self, subcategory_name, product_name):
        """åˆ¤æ–­äº§å“æ˜¯å¦æœ‰å­åˆ†ç±»ï¼Œç”¨äºç¡®å®šç›®å½•ç»“æ„"""
        # æ ¹æ®æˆ‘ä»¬è®¾è®¡çš„æ–‡ä»¶å¤¹ç»“æ„ï¼Œè¿™äº›äº§å“æœ‰å­åˆ†ç±»
        products_with_subcategories = {
            'éš”ç¦»ã€è´Ÿè·å¼€å…³': [
                'GL ç³»åˆ—éš”ç¦»å¼€å…³ï¼ˆç¥¥äº‘ 3.0ï¼‰',
                'HR17Nç³»åˆ—ç†”æ–­å™¨å¼éš”ç¦»å¼€å…³',
                'TGHRT17ç³»åˆ—ç†”æ–­å™¨å¼éš”ç¦»å¼€å…³',
                'TGHT17ç³»åˆ—éš”ç¦»å¼€å…³'
            ],
            'ç†”æ–­å™¨': [
                'RT16åˆ€å‹è§¦å¤´ç†”æ–­å™¨',
                'RT17åˆ€å‹è§¦å¤´ç†”æ–­å™¨',
                'RT18åˆ€å‹è§¦å¤´ç†”æ–­å™¨'
            ],
            'è¿‡æ¬ å‹ä¿æŠ¤å™¨': [
                'TGV1è¿‡æ¬ å‹ä¿æŠ¤å™¨',
                'TGV2è¿‡æ¬ å‹ä¿æŠ¤å™¨'
            ],
            'æµªæ¶Œä¿æŠ¤å™¨': [
                'TGS1æµªæ¶Œä¿æŠ¤å™¨',
                'TGS2æµªæ¶Œä¿æŠ¤å™¨'
            ],
            'æ¥è§¦å™¨': [
                'TGC1äº¤æµæ¥è§¦å™¨',
                'TGC2ç›´æµæ¥è§¦å™¨'
            ],
            'ç»§ç”µå™¨': [
                'TGR1æ—¶é—´ç»§ç”µå™¨',
                'TGR2ä¸­é—´ç»§ç”µå™¨'
            ]
        }
        
        # æ£€æŸ¥æ˜¯å¦åœ¨å·²çŸ¥çš„å­åˆ†ç±»äº§å“åˆ—è¡¨ä¸­
        if subcategory_name in products_with_subcategories:
            if product_name in products_with_subcategories[subcategory_name]:
                return True
        
        # æ£€æŸ¥äº§å“åç§°æ˜¯å¦åŒ…å«æ˜æ˜¾çš„å­åˆ†ç±»ç‰¹å¾
        subcategory_indicators = [
            'ç³»åˆ—', 'å‹å·', 'è§„æ ¼', 'ç±»å‹', 'ç‰ˆæœ¬', 'ä»£æ¬¡', 'ç¥¥äº‘'
        ]
        
        if any(indicator in product_name for indicator in subcategory_indicators):
            return True
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºå‹å·æ ¼å¼ï¼ˆå­—æ¯+æ•°å­—çš„ç»„åˆï¼‰
        if re.search(r'[A-Z]{2,}\d+', product_name):
            return True
        
        return False

    def get_smart_folder_path(self, category_name, subcategory_name, product_name, tab_name):
        """è·å–æ™ºèƒ½æ–‡ä»¶å¤¹è·¯å¾„ï¼Œç¡®ä¿äº§å“è¢«æ”¾å…¥æ§åˆ¶ç”µå™¨å¯¹åº”çš„æ–‡ä»¶å¤¹ä¸­"""
        try:
            # æ ¹æ®äº§å“ç±»å‹ç¡®å®šæ­£ç¡®çš„å­åˆ†ç±»
            if hasattr(self, 'current_product_box_type') and self.current_product_box_type:
                # ä½¿ç”¨å½“å‰äº§å“çš„å®¹å™¨ç±»å‹æ¥ç¡®å®šå­åˆ†ç±»
                if self.current_product_box_type == "é«˜å‹äº¤æµçœŸç©ºæ–­æµå™¨":
                    actual_subcategory = "é«˜å‹äº¤æµçœŸç©ºæ–­æµå™¨"
                else:
                    actual_subcategory = subcategory_name
            else:
                actual_subcategory = subcategory_name
            
            # æ„å»ºå±‚çº§æ–‡ä»¶å¤¹è·¯å¾„ï¼šæ§åˆ¶ç”µå™¨/å­åˆ†ç±»/äº§å“/æ–‡æ¡£ç±»å‹
            folder_path = os.path.join(self.base_dir, category_name, actual_subcategory, product_name, self.safe_filename(tab_name))
            
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            os.makedirs(folder_path, exist_ok=True)
            
            self.log(f"   ğŸ“ æ™ºèƒ½æ–‡ä»¶å¤¹è·¯å¾„: {folder_path}")
            return folder_path
            
        except Exception as e:
            self.log(f"   âŒ è·å–æ™ºèƒ½æ–‡ä»¶å¤¹è·¯å¾„å¤±è´¥: {str(e)}")
            # é™çº§åˆ°é»˜è®¤è·¯å¾„
            default_path = os.path.join(self.base_dir, self.safe_filename(tab_name))
            os.makedirs(default_path, exist_ok=True)
            return default_path

    def is_valid_product_url(self, url, title):
        """éªŒè¯æ˜¯å¦ä¸ºæœ‰æ•ˆçš„äº§å“é“¾æ¥"""
        # è¿‡æ»¤æ‰æ˜æ˜¾çš„éäº§å“é¡µé¢
        exclude_patterns = [
            r'/news/', r'/about/', r'/contact/', r'/service/', r'/download/',
            r'/support/', r'/solution/', r'/case/', r'/company/', r'/culture/',
            r'/history/', r'/honor/', r'/recruit/', r'/index\.', r'/home'
        ]
        
        for pattern in exclude_patterns:
            if re.search(pattern, url, re.IGNORECASE):
                return False
        
        # æ£€æŸ¥URLæ˜¯å¦åŒ…å«äº§å“ç›¸å…³å…³é”®è¯
        product_url_patterns = [
            r'/product/', r'/series/', r'/model/', r'/item/', r'/detail/',
            r'\.html?$', r'\.php$', r'\.asp$', r'\.aspx$'
        ]
        
        for pattern in product_url_patterns:
            if re.search(pattern, url, re.IGNORECASE):
                return True
        
        # å¦‚æœURLçœ‹èµ·æ¥åƒäº§å“é¡µé¢ï¼Œä¹Ÿè®¤ä¸ºæ˜¯æœ‰æ•ˆçš„
        if any(keyword in url.lower() for keyword in ['product', 'series', 'model', 'item', 'detail']):
            return True
        
        return True  # é»˜è®¤è®¤ä¸ºæ˜¯æœ‰æ•ˆçš„

    def test_folder_classification(self):
        """æµ‹è¯•æ–‡ä»¶å¤¹åˆ†ç±»é€»è¾‘"""
        self.log("ğŸ§ª æµ‹è¯•æ–‡ä»¶å¤¹åˆ†ç±»é€»è¾‘")
        self.log("=" * 50)
        
        # æµ‹è¯•ç”¨ä¾‹
        test_cases = [
            {
                'category': 'é…ç”µç”µå™¨',
                'subcategory': 'éš”ç¦»ã€è´Ÿè·å¼€å…³',
                'product': 'GL ç³»åˆ—éš”ç¦»å¼€å…³ï¼ˆç¥¥äº‘ 3.0ï¼‰',
                'tab': 'äº§å“æ ·æœ¬',
                'expected_has_sub': True
            },
            {
                'category': 'é…ç”µç”µå™¨',
                'subcategory': 'éš”ç¦»ã€è´Ÿè·å¼€å…³',
                'product': 'HR17Nç³»åˆ—ç†”æ–­å™¨å¼éš”ç¦»å¼€å…³',
                'tab': 'æ£€æµ‹æŠ¥å‘Š',
                'expected_has_sub': True
            },
            {
                'category': 'ç»ˆç«¯ç”µå™¨',
                'subcategory': 'è¿‡æ¬ å‹ä¿æŠ¤å™¨',
                'product': 'TGV1è¿‡æ¬ å‹ä¿æŠ¤å™¨',
                'tab': 'è®¤è¯è¯ä¹¦',
                'expected_has_sub': True
            },
            {
                'category': 'æ§åˆ¶ç”µå™¨',
                'subcategory': 'æ¥è§¦å™¨',
                'product': 'æ™®é€šæ¥è§¦å™¨',
                'tab': 'äº§å“æ ·æœ¬',
                'expected_has_sub': False
            }
        ]
        
        for i, case in enumerate(test_cases, 1):
            self.log(f"\nğŸ” æµ‹è¯•ç”¨ä¾‹ {i}:")
            self.log(f"   åˆ†ç±»: {case['category']}")
            self.log(f"   å­åˆ†ç±»: {case['subcategory']}")
            self.log(f"   äº§å“: {case['product']}")
            self.log(f"   æ ‡ç­¾é¡µ: {case['tab']}")
            
            # æµ‹è¯•æ˜¯å¦æœ‰å­åˆ†ç±»
            has_sub = self.is_product_with_subcategories(case['subcategory'], case['product'])
            self.log(f"   åˆ¤æ–­æœ‰å­åˆ†ç±»: {has_sub} (æœŸæœ›: {case['expected_has_sub']})")
            
            # æµ‹è¯•æ–‡ä»¶å¤¹è·¯å¾„
            folder_path = self.get_smart_folder_path(
                case['category'], 
                case['subcategory'], 
                case['product'], 
                case['tab']
            )
            
            # æå–æ–‡ä»¶å¤¹åç§°
            folder_name = os.path.basename(folder_path)
            self.log(f"   ç”Ÿæˆçš„æ–‡ä»¶å¤¹å: {folder_name}")
            
            # éªŒè¯ç»“æœ
            if has_sub == case['expected_has_sub']:
                self.log(f"   âœ… å­åˆ†ç±»åˆ¤æ–­æ­£ç¡®")
            else:
                self.log(f"   âŒ å­åˆ†ç±»åˆ¤æ–­é”™è¯¯")
            
            # éªŒè¯æ–‡ä»¶å¤¹åç§°æ ¼å¼
            if has_sub:
                expected_format = f"{case['category']}-{case['subcategory']}-{case['product']}-{case['tab']}"
            else:
                expected_format = f"{case['category']}-{case['subcategory']}-{case['tab']}"
            
            if folder_name == expected_format:
                self.log(f"   âœ… æ–‡ä»¶å¤¹åç§°æ ¼å¼æ­£ç¡®")
            else:
                self.log(f"   âŒ æ–‡ä»¶å¤¹åç§°æ ¼å¼é”™è¯¯ï¼ŒæœŸæœ›: {expected_format}")
        
        self.log("\n" + "=" * 50)
        self.log("ğŸ§ª æ–‡ä»¶å¤¹åˆ†ç±»é€»è¾‘æµ‹è¯•å®Œæˆ")

if __name__ == "__main__":
    spider = TengenSpider()
    
    # å¦‚æœä¼ å…¥ --test å‚æ•°ï¼Œåˆ™è¿è¡Œæµ‹è¯•
    import sys
    if len(sys.argv) > 1 and sys.argv[1] == '--test':
        spider.test_folder_classification()
    else:
        spider.run()
